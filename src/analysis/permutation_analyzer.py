"""
T009: Permutation Importance ë¶„ì„ì„ í†µí•œ íŠ¹ì„± ì¤‘ìš”ë„ í‰ê°€

ì´ ëª¨ë“ˆì€ Permutation Importanceë¥¼ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
SHAP ë¶„ì„ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•´ì„ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.inspection import permutation_importance
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score, make_scorer
import warnings
from pathlib import Path
import mlflow
import wandb
from typing import Dict, List, Tuple, Optional, Union
import logging

class PermutationAnalyzer:
    """Permutation Importanceë¥¼ í†µí•œ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, config=None, experiment_tracker=None):
        """
        Permutation Importance ë¶„ì„ê¸° ì´ˆê¸°í™”

        Args:
            config: ì„¤ì • ê°ì²´
            experiment_tracker: ì‹¤í—˜ ì¶”ì ê¸° ê°ì²´
        """
        self.config = config
        self.experiment_tracker = experiment_tracker
        self.logger = logging.getLogger(__name__)

        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
        if config:
            self.plots_dir = Path(config.get_paths().get('plots', 'plots'))
            self.experiments_dir = Path(config.get_paths().get('experiments', 'experiments'))
        else:
            self.plots_dir = Path('plots')
            self.experiments_dir = Path('experiments')

        self.permutation_dir = self.plots_dir / 'permutation_analysis'
        self.permutation_dir.mkdir(parents=True, exist_ok=True)

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'DejaVu Sans'
        warnings.filterwarnings('ignore', category=UserWarning)

        self.results = {}

    def calculate_permutation_importance(
        self,
        model,
        X_val: pd.DataFrame,
        y_val: pd.Series,
        scoring: str = 'f1_macro',
        n_repeats: int = 10,
        random_state: int = 42
    ) -> Dict:
        """
        Permutation Importance ê³„ì‚°

        Args:
            model: í•™ìŠµëœ ëª¨ë¸
            X_val: ê²€ì¦ ë°ì´í„° íŠ¹ì„±
            y_val: ê²€ì¦ ë°ì´í„° ë ˆì´ë¸”
            scoring: í‰ê°€ ì§€í‘œ
            n_repeats: ë°˜ë³µ íšŸìˆ˜
            random_state: ëœë¤ ì‹œë“œ

        Returns:
            Permutation Importance ê²°ê³¼
        """
        try:
            self.logger.info(f"ğŸ”„ Permutation Importance ê³„ì‚° ì‹œì‘...")
            self.logger.info(f"   - íŠ¹ì„± ìˆ˜: {len(X_val.columns)}")
            self.logger.info(f"   - ê²€ì¦ ë°ì´í„° í¬ê¸°: {len(X_val)}")
            self.logger.info(f"   - ë°˜ë³µ íšŸìˆ˜: {n_repeats}")
            self.logger.info(f"   - í‰ê°€ ì§€í‘œ: {scoring}")

            # Permutation Importance ê³„ì‚°
            perm_importance = permutation_importance(
                model, X_val, y_val,
                scoring=scoring,
                n_repeats=n_repeats,
                random_state=random_state,
                n_jobs=-1
            )

            # ê²°ê³¼ ì •ë¦¬
            importance_mean = perm_importance.importances_mean
            importance_std = perm_importance.importances_std

            # DataFrameìœ¼ë¡œ ë³€í™˜
            perm_df = pd.DataFrame({
                'feature': X_val.columns,
                'importance_mean': importance_mean,
                'importance_std': importance_std,
                'importance_abs': np.abs(importance_mean)  # ì ˆëŒ“ê°’
            })

            # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            perm_df = perm_df.sort_values('importance_abs', ascending=False).reset_index(drop=True)

            results = {
                'permutation_df': perm_df,
                'raw_importances': perm_importance.importances,
                'baseline_score': self._get_baseline_score(model, X_val, y_val, scoring),
                'scoring_metric': scoring,
                'n_repeats': n_repeats
            }

            self.logger.info(f"âœ… Permutation Importance ê³„ì‚° ì™„ë£Œ")
            self.logger.info(f"   - ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±: {perm_df.iloc[0]['feature']} (ì¤‘ìš”ë„: {perm_df.iloc[0]['importance_mean']:.4f})")
            self.logger.info(f"   - ë² ì´ìŠ¤ë¼ì¸ ì ìˆ˜: {results['baseline_score']:.4f}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ Permutation Importance ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            raise

    def _get_baseline_score(self, model, X_val, y_val, scoring):
        """ë² ì´ìŠ¤ë¼ì¸ ì ìˆ˜ ê³„ì‚°"""
        try:
            if scoring == 'f1_macro':
                y_pred = model.predict(X_val)
                return f1_score(y_val, y_pred, average='macro')
            else:
                return model.score(X_val, y_val)
        except Exception as e:
            self.logger.warning(f"ë² ì´ìŠ¤ë¼ì¸ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 0.0

    def create_permutation_plots(
        self,
        perm_results: Dict,
        model_name: str = "RandomForest",
        top_k: int = 20
    ) -> Dict[str, str]:
        """
        Permutation Importance ì‹œê°í™”

        Args:
            perm_results: Permutation Importance ê²°ê³¼
            model_name: ëª¨ë¸ ì´ë¦„
            top_k: ìƒìœ„ Kê°œ íŠ¹ì„±

        Returns:
            ìƒì„±ëœ í”Œë¡¯ íŒŒì¼ ê²½ë¡œë“¤
        """
        plot_paths = {}
        perm_df = perm_results['permutation_df']
        model_dir = self.permutation_dir / f"{model_name.lower()}-permutation"
        model_dir.mkdir(exist_ok=True)

        try:
            # 1. ìƒìœ„ íŠ¹ì„± ì¤‘ìš”ë„ ë°” í”Œë¡¯
            plt.figure(figsize=(12, 8))
            top_features = perm_df.head(top_k)

            bars = plt.barh(range(len(top_features)), top_features['importance_mean'],
                           xerr=top_features['importance_std'], alpha=0.7)
            plt.yticks(range(len(top_features)), top_features['feature'])
            plt.xlabel('Permutation Importance')
            plt.title(f'{model_name}\nTop {top_k} Feature Permutation Importance')
            plt.gca().invert_yaxis()

            # ìƒ‰ìƒ êµ¬ë¶„ (ì–‘ìˆ˜/ìŒìˆ˜)
            for i, (bar, importance) in enumerate(zip(bars, top_features['importance_mean'])):
                if importance >= 0:
                    bar.set_color('skyblue')
                else:
                    bar.set_color('lightcoral')

            plt.tight_layout()
            plot_path = model_dir / 'top_features_importance.png'
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_paths['top_features'] = str(plot_path)

            # 2. ì¤‘ìš”ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            plt.figure(figsize=(10, 6))
            plt.hist(perm_df['importance_mean'], bins=30, alpha=0.7, color='lightblue', edgecolor='black')
            plt.axvline(0, color='red', linestyle='--', alpha=0.7, label='Zero Importance')
            plt.xlabel('Permutation Importance')
            plt.ylabel('Number of Features')
            plt.title(f'{model_name}\nDistribution of Permutation Importance')
            plt.legend()
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            plot_path = model_dir / 'importance_distribution.png'
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_paths['distribution'] = str(plot_path)

            # 3. ì¤‘ìš”ë„ vs í‘œì¤€í¸ì°¨ ì‚°ì ë„
            plt.figure(figsize=(10, 8))
            scatter = plt.scatter(perm_df['importance_mean'], perm_df['importance_std'],
                                alpha=0.6, c=perm_df['importance_abs'], cmap='viridis')
            plt.colorbar(scatter, label='Absolute Importance')

            # ìƒìœ„ íŠ¹ì„± ë¼ë²¨ë§
            for i, row in perm_df.head(10).iterrows():
                plt.annotate(row['feature'],
                           (row['importance_mean'], row['importance_std']),
                           xytext=(5, 5), textcoords='offset points',
                           fontsize=8, alpha=0.7)

            plt.xlabel('Mean Permutation Importance')
            plt.ylabel('Standard Deviation')
            plt.title(f'{model_name}\nPermutation Importance: Mean vs Std')
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            plot_path = model_dir / 'importance_scatter.png'
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_paths['scatter'] = str(plot_path)

            # 4. ë°•ìŠ¤í”Œë¡¯ (ìƒìœ„ íŠ¹ì„±ë“¤ì˜ ì¤‘ìš”ë„ ë¶„í¬)
            plt.figure(figsize=(12, 8))
            top_n = min(15, len(perm_df))
            box_data = []
            box_labels = []

            for idx in range(top_n):
                feature_idx = list(perm_df['feature']).index(perm_df.iloc[idx]['feature'])
                feature_importances = perm_results['raw_importances'][feature_idx]
                box_data.append(feature_importances)
                box_labels.append(perm_df.iloc[idx]['feature'])

            plt.boxplot(box_data, labels=box_labels)
            plt.xticks(rotation=45, ha='right')
            plt.ylabel('Permutation Importance')
            plt.title(f'{model_name}\nTop {top_n} Features Importance Distribution')
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            plot_path = model_dir / 'importance_boxplot.png'
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_paths['boxplot'] = str(plot_path)

            self.logger.info(f"âœ… {len(plot_paths)}ê°œ Permutation ì‹œê°í™” ì™„ë£Œ: {model_dir}")

        except Exception as e:
            self.logger.error(f"âŒ Permutation ì‹œê°í™” ì˜¤ë¥˜: {str(e)}")

        return plot_paths

    def compare_with_shap(
        self,
        perm_df: pd.DataFrame,
        shap_df: pd.DataFrame,
        model_name: str = "RandomForest"
    ) -> Dict:
        """
        Permutation Importanceì™€ SHAP ì¤‘ìš”ë„ ë¹„êµ

        Args:
            perm_df: Permutation Importance DataFrame
            shap_df: SHAP ì¤‘ìš”ë„ DataFrame
            model_name: ëª¨ë¸ ì´ë¦„

        Returns:
            ë¹„êµ ê²°ê³¼ ë° ì‹œê°í™” ê²½ë¡œ
        """
        try:
            self.logger.info("ğŸ”„ Permutation vs SHAP ë¹„êµ ë¶„ì„ ì‹œì‘...")

            # ê³µí†µ íŠ¹ì„±ë§Œ ì„ íƒ
            common_features = set(perm_df['feature']).intersection(set(shap_df['feature']))

            if not common_features:
                self.logger.warning("ê³µí†µ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
                return {}

            # ë°ì´í„° ì •ë¦¬
            perm_common = perm_df[perm_df['feature'].isin(common_features)].set_index('feature')
            shap_common = shap_df[shap_df['feature'].isin(common_features)].set_index('feature')

            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation = np.corrcoef(
                perm_common.loc[common_features, 'importance_abs'].values,
                shap_common.loc[common_features, 'importance'].values
            )[0, 1]

            # ë¹„êµ DataFrame ìƒì„±
            comparison_df = pd.DataFrame({
                'feature': list(common_features),
                'permutation_importance': [perm_common.loc[f, 'importance_abs'] for f in common_features],
                'shap_importance': [shap_common.loc[f, 'importance'] for f in common_features]
            })

            # ìˆœìœ„ ê³„ì‚°
            comparison_df['perm_rank'] = comparison_df['permutation_importance'].rank(ascending=False)
            comparison_df['shap_rank'] = comparison_df['shap_importance'].rank(ascending=False)
            comparison_df['rank_diff'] = abs(comparison_df['perm_rank'] - comparison_df['shap_rank'])

            # ì‹œê°í™”
            model_dir = self.permutation_dir / f"{model_name.lower()}-comparison"
            model_dir.mkdir(exist_ok=True)

            # 1. ì‚°ì ë„
            plt.figure(figsize=(10, 8))
            scatter = plt.scatter(comparison_df['permutation_importance'],
                                comparison_df['shap_importance'],
                                alpha=0.6, s=60)

            # ìƒìœ„ íŠ¹ì„± ë¼ë²¨ë§
            top_features = comparison_df.nlargest(10, 'permutation_importance')
            for _, row in top_features.iterrows():
                plt.annotate(row['feature'],
                           (row['permutation_importance'], row['shap_importance']),
                           xytext=(5, 5), textcoords='offset points',
                           fontsize=8, alpha=0.7)

            plt.xlabel('Permutation Importance')
            plt.ylabel('SHAP Importance')
            plt.title(f'{model_name}\nPermutation vs SHAP Importance\n(Correlation: {correlation:.3f})')

            # ëŒ€ê°ì„  ì¶”ê°€
            max_val = max(comparison_df['permutation_importance'].max(),
                         comparison_df['shap_importance'].max())
            plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Perfect Correlation')
            plt.legend()
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            scatter_path = model_dir / 'importance_comparison.png'
            plt.savefig(scatter_path, dpi=150, bbox_inches='tight')
            plt.close()

            # 2. ìˆœìœ„ ë¹„êµ
            plt.figure(figsize=(12, 8))
            top_n = min(20, len(comparison_df))
            top_comparison = comparison_df.nsmallest(top_n, 'rank_diff')

            x = range(len(top_comparison))
            width = 0.35

            plt.bar([i - width/2 for i in x], top_comparison['perm_rank'],
                   width, label='Permutation Rank', alpha=0.7)
            plt.bar([i + width/2 for i in x], top_comparison['shap_rank'],
                   width, label='SHAP Rank', alpha=0.7)

            plt.xlabel('Features')
            plt.ylabel('Importance Rank')
            plt.title(f'{model_name}\nRank Comparison (Top {top_n} Most Consistent)')
            plt.xticks(x, top_comparison['feature'], rotation=45, ha='right')
            plt.legend()
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            rank_path = model_dir / 'rank_comparison.png'
            plt.savefig(rank_path, dpi=150, bbox_inches='tight')
            plt.close()

            results = {
                'comparison_df': comparison_df,
                'correlation': correlation,
                'common_features_count': len(common_features),
                'plot_paths': {
                    'scatter': str(scatter_path),
                    'rank_comparison': str(rank_path)
                }
            }

            self.logger.info(f"âœ… Permutation vs SHAP ë¹„êµ ì™„ë£Œ")
            self.logger.info(f"   - ìƒê´€ê´€ê³„: {correlation:.3f}")
            self.logger.info(f"   - ê³µí†µ íŠ¹ì„± ìˆ˜: {len(common_features)}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ Permutation vs SHAP ë¹„êµ ì˜¤ë¥˜: {str(e)}")
            return {}

    def analyze_feature_stability(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        model_params: Dict = None,
        n_splits: int = 5,
        random_state: int = 42
    ) -> Dict:
        """
        êµì°¨ê²€ì¦ì„ í†µí•œ íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„± ë¶„ì„

        Args:
            X_train: í›ˆë ¨ ë°ì´í„° íŠ¹ì„±
            y_train: í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸”
            model_params: ëª¨ë¸ íŒŒë¼ë¯¸í„°
            n_splits: êµì°¨ê²€ì¦ ë¶„í•  ìˆ˜
            random_state: ëœë¤ ì‹œë“œ

        Returns:
            ì•ˆì •ì„± ë¶„ì„ ê²°ê³¼
        """
        try:
            self.logger.info("ğŸ”„ íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„± ë¶„ì„ ì‹œì‘...")

            from sklearn.model_selection import KFold

            if model_params is None:
                model_params = {
                    'n_estimators': 100,
                    'max_depth': 10,
                    'random_state': random_state,
                    'class_weight': 'balanced'
                }

            # KFold ì„¤ì •
            kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)

            importance_across_folds = []

            for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):
                self.logger.info(f"   - Fold {fold + 1}/{n_splits} ì²˜ë¦¬ ì¤‘...")

                X_fold_train = X_train.iloc[train_idx]
                X_fold_val = X_train.iloc[val_idx]
                y_fold_train = y_train.iloc[train_idx]
                y_fold_val = y_train.iloc[val_idx]

                # ëª¨ë¸ í›ˆë ¨
                model = RandomForestClassifier(**model_params)
                model.fit(X_fold_train, y_fold_train)

                # Permutation Importance ê³„ì‚°
                perm_result = self.calculate_permutation_importance(
                    model, X_fold_val, y_fold_val,
                    scoring='f1_macro', n_repeats=5
                )

                fold_importance = perm_result['permutation_df'][['feature', 'importance_mean']].copy()
                fold_importance['fold'] = fold
                importance_across_folds.append(fold_importance)

            # ê²°ê³¼ í†µí•©
            all_importance = pd.concat(importance_across_folds, ignore_index=True)

            # ì•ˆì •ì„± í†µê³„ ê³„ì‚°
            stability_stats = all_importance.groupby('feature')['importance_mean'].agg([
                'mean', 'std', 'min', 'max'
            ]).reset_index()

            stability_stats['cv'] = stability_stats['std'] / (stability_stats['mean'] + 1e-8)  # ë³€ë™ê³„ìˆ˜
            stability_stats = stability_stats.sort_values('mean', ascending=False)

            # ì‹œê°í™”
            model_dir = self.permutation_dir / "stability_analysis"
            model_dir.mkdir(exist_ok=True)

            # 1. ì•ˆì •ì„± íˆíŠ¸ë§µ
            pivot_data = all_importance.pivot(index='feature', columns='fold', values='importance_mean')

            plt.figure(figsize=(12, 16))
            sns.heatmap(pivot_data.iloc[:30], annot=False, cmap='viridis',
                       cbar_kws={'label': 'Permutation Importance'})
            plt.title('Feature Importance Across CV Folds\n(Top 30 Features)')
            plt.xlabel('Fold')
            plt.ylabel('Feature')

            plt.tight_layout()
            heatmap_path = model_dir / 'stability_heatmap.png'
            plt.savefig(heatmap_path, dpi=150, bbox_inches='tight')
            plt.close()

            # 2. ë³€ë™ê³„ìˆ˜ vs í‰ê·  ì¤‘ìš”ë„
            plt.figure(figsize=(10, 8))
            scatter = plt.scatter(stability_stats['mean'], stability_stats['cv'],
                                alpha=0.6, s=60)

            # ìƒìœ„ íŠ¹ì„± ë¼ë²¨ë§
            top_stable = stability_stats.head(10)
            for _, row in top_stable.iterrows():
                plt.annotate(row['feature'],
                           (row['mean'], row['cv']),
                           xytext=(5, 5), textcoords='offset points',
                           fontsize=8, alpha=0.7)

            plt.xlabel('Mean Importance')
            plt.ylabel('Coefficient of Variation')
            plt.title('Feature Stability Analysis\nMean Importance vs Variability')
            plt.grid(True, alpha=0.3)

            plt.tight_layout()
            stability_path = model_dir / 'stability_scatter.png'
            plt.savefig(stability_path, dpi=150, bbox_inches='tight')
            plt.close()

            results = {
                'stability_stats': stability_stats,
                'all_importance': all_importance,
                'n_splits': n_splits,
                'plot_paths': {
                    'heatmap': str(heatmap_path),
                    'stability': str(stability_path)
                }
            }

            self.logger.info("âœ… íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„± ë¶„ì„ ì™„ë£Œ")
            self.logger.info(f"   - ê°€ì¥ ì•ˆì •í•œ íŠ¹ì„±: {stability_stats.iloc[0]['feature']}")
            self.logger.info(f"   - í‰ê·  ë³€ë™ê³„ìˆ˜: {stability_stats['cv'].mean():.3f}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ ì•ˆì •ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {}

    def analyze_permutation_interpretability(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_test: pd.DataFrame = None,
        y_test: pd.Series = None,
        model_params: Dict = None,
        shap_results: Dict = None
    ) -> Dict:
        """
        ì¢…í•©ì ì¸ Permutation Importance í•´ì„ì„± ë¶„ì„

        Args:
            X_train: í›ˆë ¨ ë°ì´í„° íŠ¹ì„±
            y_train: í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸”
            X_test: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŠ¹ì„±
            y_test: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë ˆì´ë¸”
            model_params: ëª¨ë¸ íŒŒë¼ë¯¸í„°
            shap_results: SHAP ë¶„ì„ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)

        Returns:
            ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        try:
            self.logger.info("ğŸš€ T009: Permutation Importance ì¢…í•© ë¶„ì„ ì‹œì‘")

            # ê¸°ë³¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°
            if model_params is None:
                model_params = {
                    'n_estimators': 100,
                    'max_depth': 10,
                    'random_state': 42,
                    'class_weight': 'balanced'
                }

            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í›ˆë ¨ ë°ì´í„°ì—ì„œ ë¶„í• 
            if X_test is None or y_test is None:
                from sklearn.model_selection import train_test_split
                X_train_split, X_test, y_train_split, y_test = train_test_split(
                    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train
                )
            else:
                X_train_split = X_train
                y_train_split = y_train

            # ëª¨ë¸ í›ˆë ¨
            self.logger.info("ğŸ”„ RandomForest ëª¨ë¸ í›ˆë ¨...")
            model = RandomForestClassifier(**model_params)
            model.fit(X_train_split, y_train_split)

            # 1. Permutation Importance ê³„ì‚°
            perm_results = self.calculate_permutation_importance(
                model, X_test, y_test,
                scoring='f1_macro', n_repeats=10
            )

            # 2. ì‹œê°í™” ìƒì„±
            plot_paths = self.create_permutation_plots(
                perm_results, model_name="RandomForest-Balanced"
            )

            # 3. SHAPê³¼ ë¹„êµ (ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
            comparison_results = {}
            if shap_results:
                self.logger.info("ğŸ”„ SHAP vs Permutation ë¹„êµ...")
                comparison_results = self.compare_with_shap(
                    perm_results['permutation_df'],
                    shap_results.get('global_importance', pd.DataFrame()),
                    model_name="RandomForest-Balanced"
                )

            # 4. ì•ˆì •ì„± ë¶„ì„
            stability_results = self.analyze_feature_stability(
                X_train_split, y_train_split, model_params
            )

            # 5. ê²°ê³¼ í†µí•©
            results = {
                'permutation_importance': perm_results,
                'plot_paths': plot_paths,
                'comparison_with_shap': comparison_results,
                'stability_analysis': stability_results,
                'model_performance': {
                    'baseline_f1_macro': perm_results['baseline_score'],
                    'model_params': model_params
                }
            }

            # ì‹¤í—˜ ì¶”ì 
            if self.experiment_tracker:
                self._log_to_experiment_tracker(results)

            self.results = results

            self.logger.info("ğŸ‰ T009: Permutation Importance ë¶„ì„ ì™„ë£Œ!")
            return results

        except Exception as e:
            self.logger.error(f"âŒ T009 ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            raise

    def _log_to_experiment_tracker(self, results: Dict):
        """ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œì— ê²°ê³¼ ë¡œê·¸"""
        try:
            if not self.experiment_tracker:
                return

            # MLflow ë¡œê¹…
            if hasattr(self.experiment_tracker, 'mlflow_client'):
                with mlflow.start_run(run_name="T009_Permutation_Analysis"):
                    # ë©”íŠ¸ë¦­ ë¡œê¹…
                    mlflow.log_metric("baseline_f1_macro", results['model_performance']['baseline_f1_macro'])
                    mlflow.log_metric("n_features", len(results['permutation_importance']['permutation_df']))

                    # ìƒìœ„ íŠ¹ì„± ë¡œê¹…
                    top_features = results['permutation_importance']['permutation_df'].head(5)
                    for idx, row in top_features.iterrows():
                        mlflow.log_metric(f"top_{idx+1}_importance", row['importance_mean'])
                        mlflow.log_param(f"top_{idx+1}_feature", row['feature'])

                    # ì‹œê°í™” ë¡œê¹…
                    for plot_name, plot_path in results['plot_paths'].items():
                        mlflow.log_artifact(plot_path, f"permutation_plots/{plot_name}")

            # WandB ë¡œê¹…
            if hasattr(self.experiment_tracker, 'wandb_run'):
                wandb.log({
                    "permutation/baseline_f1_macro": results['model_performance']['baseline_f1_macro'],
                    "permutation/n_features": len(results['permutation_importance']['permutation_df']),
                })

                # ì‹œê°í™” ë¡œê¹…
                for plot_name, plot_path in results['plot_paths'].items():
                    wandb.log({f"permutation/{plot_name}": wandb.Image(plot_path)})

        except Exception as e:
            self.logger.warning(f"ì‹¤í—˜ ì¶”ì  ë¡œê¹… ì‹¤íŒ¨: {str(e)}")

    def print_summary(self, results: Dict):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        try:
            print("\n" + "="*80)
            print("ğŸ¯ T009: PERMUTATION IMPORTANCE ë¶„ì„ ê²°ê³¼ ìš”ì•½")
            print("="*80)

            perm_df = results['permutation_importance']['permutation_df']
            baseline_score = results['model_performance']['baseline_f1_macro']

            print(f"ğŸ“Š ê¸°ë³¸ ì •ë³´:")
            print(f"   â€¢ ë² ì´ìŠ¤ë¼ì¸ F1 Macro: {baseline_score:.4f}")
            print(f"   â€¢ ë¶„ì„ëœ íŠ¹ì„± ìˆ˜: {len(perm_df)}")
            print(f"   â€¢ ì–‘ì˜ ì¤‘ìš”ë„ íŠ¹ì„±: {(perm_df['importance_mean'] > 0).sum()}ê°œ")
            print(f"   â€¢ ìŒì˜ ì¤‘ìš”ë„ íŠ¹ì„±: {(perm_df['importance_mean'] < 0).sum()}ê°œ")

            print(f"\nğŸ† ìƒìœ„ 10ê°œ ì¤‘ìš”í•œ íŠ¹ì„±:")
            for idx, row in perm_df.head(10).iterrows():
                print(f"   {idx+1:2d}. {row['feature']:15s} : {row['importance_mean']:8.4f} (Â±{row['importance_std']:.4f})")

            print(f"\nğŸ“‰ í•˜ìœ„ 5ê°œ íŠ¹ì„± (ì„±ëŠ¥ ì €í•˜ ìš”ì¸):")
            bottom_features = perm_df[perm_df['importance_mean'] < 0].tail(5)
            for idx, row in bottom_features.iterrows():
                print(f"   â€¢ {row['feature']:15s} : {row['importance_mean']:8.4f} (Â±{row['importance_std']:.4f})")

            # SHAP ë¹„êµ ê²°ê³¼
            if results.get('comparison_with_shap'):
                correlation = results['comparison_with_shap']['correlation']
                print(f"\nğŸ”— SHAP vs Permutation ìƒê´€ê´€ê³„: {correlation:.3f}")
                if correlation > 0.7:
                    print("   âœ… ë‘ ë°©ë²•ì´ ë†’ì€ ì¼ì¹˜ì„±ì„ ë³´ì…ë‹ˆë‹¤.")
                elif correlation > 0.5:
                    print("   âš ï¸  ë‘ ë°©ë²•ì´ ì¤‘ê°„ ì •ë„ ì¼ì¹˜ì„±ì„ ë³´ì…ë‹ˆë‹¤.")
                else:
                    print("   âŒ ë‘ ë°©ë²• ê°„ ì°¨ì´ê°€ í½ë‹ˆë‹¤. ì¶”ê°€ ë¶„ì„ í•„ìš”.")

            # ì•ˆì •ì„± ë¶„ì„ ê²°ê³¼
            if results.get('stability_analysis'):
                stability_stats = results['stability_analysis']['stability_stats']
                avg_cv = stability_stats['cv'].mean()
                print(f"\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„±:")
                print(f"   â€¢ í‰ê·  ë³€ë™ê³„ìˆ˜: {avg_cv:.3f}")
                if avg_cv < 0.3:
                    print("   âœ… íŠ¹ì„± ì¤‘ìš”ë„ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤.")
                elif avg_cv < 0.5:
                    print("   âš ï¸  íŠ¹ì„± ì¤‘ìš”ë„ê°€ ë³´í†µ ìˆ˜ì¤€ìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.")
                else:
                    print("   âŒ íŠ¹ì„± ì¤‘ìš”ë„ê°€ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.")

            print(f"\nğŸ“ˆ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
            # ì„±ëŠ¥ì— ê°€ì¥ ë„ì›€ë˜ëŠ” íŠ¹ì„±
            best_feature = perm_df.iloc[0]
            print(f"   â€¢ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±: {best_feature['feature']} (ì„±ëŠ¥ ê¸°ì—¬ë„: {best_feature['importance_mean']:.4f})")

            # ë…¸ì´ì¦ˆ íŠ¹ì„±
            noise_features = perm_df[perm_df['importance_mean'] < 0]
            if len(noise_features) > 0:
                print(f"   â€¢ ë…¸ì´ì¦ˆ íŠ¹ì„± ìˆ˜: {len(noise_features)}ê°œ (ì œê±° ê³ ë ¤ ëŒ€ìƒ)")

            # ì¤‘ìš” íŠ¹ì„± ì§‘ì¤‘ë„
            top_10_importance = perm_df.head(10)['importance_mean'].sum()
            total_positive_importance = perm_df[perm_df['importance_mean'] > 0]['importance_mean'].sum()
            if total_positive_importance > 0:
                concentration = top_10_importance / total_positive_importance
                print(f"   â€¢ ìƒìœ„ 10ê°œ íŠ¹ì„± ì§‘ì¤‘ë„: {concentration:.1%}")

            print(f"\nğŸ“ ìƒì„±ëœ ì‹œê°í™”:")
            for plot_name, plot_path in results['plot_paths'].items():
                print(f"   â€¢ {plot_name}: {plot_path}")

            print("\n" + "="*80)

        except Exception as e:
            print(f"âŒ ìš”ì•½ ì¶œë ¥ ì˜¤ë¥˜: {str(e)}")