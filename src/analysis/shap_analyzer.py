"""
SHAP ë¶„ì„ ëª¨ë“ˆ (SHAP Analysis)

ì´ ëª¨ë“ˆì€ SHAP(SHapley Additive exPlanations)ë¥¼ í™œìš©í•œ ëª¨ë¸ í•´ì„ì„± ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
- ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ (Global Feature Importance)
- í´ë˜ìŠ¤ë³„ SHAP ê°’ ë¶„ì„
- ê°œë³„ ì˜ˆì¸¡ í•´ì„ (Local Explanations)
- SHAP ì‹œê°í™” ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±

ì‘ì„±ì: Claude
ë‚ ì§œ: 2024-01-01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from typing import Dict, List, Tuple, Optional, Any, Union
import warnings
warnings.filterwarnings('ignore')

from ..tracking.experiment_tracker import ExperimentTracker
from ..utils.config import Config

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans', 'Malgun Gothic', 'AppleGothic']
plt.rcParams['axes.unicode_minus'] = False

class SHAPAnalyzer:
    """
    SHAPë¥¼ í™œìš©í•œ ëª¨ë¸ í•´ì„ì„± ë¶„ì„ í´ë˜ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    1. ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
    2. í´ë˜ìŠ¤ë³„ SHAP ê°’ ë¶„ì„
    3. ê°œë³„ ì˜ˆì¸¡ í•´ì„
    4. SHAP ê¸°ë°˜ íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„
    5. ë¬¸ì œ í´ë˜ìŠ¤ íŠ¹í™” í•´ì„
    """

    def __init__(self, config: Config = None, experiment_tracker: ExperimentTracker = None):
        self.config = config or Config()
        self.tracker = experiment_tracker
        self.shap_values = {}
        self.explainers = {}
        self.feature_importance = {}
        self.class_insights = {}
        self.recommendations = []

    def analyze_model_interpretability(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_test: pd.DataFrame = None,
        y_test: pd.Series = None,
        models: Dict[str, Any] = None,
        problem_classes: List[int] = None,
        top_features: int = 20
    ) -> Dict[str, Any]:
        """
        SHAPë¥¼ í™œìš©í•œ ì¢…í•© ëª¨ë¸ í•´ì„ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            X_train: í›ˆë ¨ ë°ì´í„° íŠ¹ì„±
            y_train: í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸”
            X_test: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŠ¹ì„±
            y_test: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë ˆì´ë¸”
            models: ë¶„ì„í•  ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
            problem_classes: íŠ¹ë³„íˆ ë¶„ì„í•  ë¬¸ì œ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
            top_features: ìƒìœ„ ì¤‘ìš” íŠ¹ì„± ê°œìˆ˜

        Returns:
            Dict: SHAP ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ” SHAP ë¶„ì„ì„ í†µí•œ ëª¨ë¸ í•´ì„ì„± ê°•í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        if self.tracker:
            self.tracker.start_run(
                run_name="shap_interpretability_analysis",
                description="SHAPë¥¼ í™œìš©í•œ ëª¨ë¸ í•´ì„ì„± ë° íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„",
                tags={"analysis_type": "shap_interpretability", "task": "T008"}
            )

        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        if models is None:
            models = {
                'RandomForest_Balanced': RandomForestClassifier(
                    n_estimators=100,
                    class_weight='balanced',
                    random_state=42,
                    max_depth=10  # SHAP ê³„ì‚° ì†ë„ë¥¼ ìœ„í•´ ê¹Šì´ ì œí•œ
                )
            }

        # ë°ì´í„° ë¶„í•  (í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
        if X_test is None or y_test is None:
            X_train_split, X_test, y_train_split, y_test = train_test_split(
                X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
            )
            X_train = X_train_split
            y_train = y_train_split

        # ê¸°ë³¸ ë¬¸ì œ í´ë˜ìŠ¤ ì„¤ì • (T007 ê²°ê³¼ ê¸°ë°˜)
        if problem_classes is None:
            problem_classes = [1, 0, 2]  # T007ì—ì„œ ì‹ë³„ëœ ìµœì € ì„±ëŠ¥ í´ë˜ìŠ¤

        print(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(models)}ê°œ ëª¨ë¸, {len(problem_classes)}ê°œ ë¬¸ì œ í´ë˜ìŠ¤")
        print(f"ğŸ¯ íŠ¹ë³„ ë¶„ì„ í´ë˜ìŠ¤: {problem_classes}")

        # ê° ëª¨ë¸ë³„ SHAP ë¶„ì„
        model_results = {}
        for model_name, model in models.items():
            print(f"\nğŸ¤– {model_name} ëª¨ë¸ SHAP ë¶„ì„ ì¤‘...")

            # ëª¨ë¸ í›ˆë ¨
            model.fit(X_train, y_train)

            # SHAP ë¶„ì„ ìˆ˜í–‰
            shap_result = self._analyze_model_with_shap(
                model, X_train, X_test, y_train, y_test, model_name,
                problem_classes, top_features
            )

            model_results[model_name] = shap_result

        # í´ë˜ìŠ¤ë³„ SHAP ì¸ì‚¬ì´íŠ¸ ìƒì„±
        class_insights = self._generate_class_insights(model_results, problem_classes)

        # íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„
        interaction_analysis = self._analyze_feature_interactions(
            model_results, X_train, top_features
        )

        # SHAP ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±
        self._generate_shap_recommendations(model_results, class_insights, interaction_analysis)

        # ì‹œê°í™” ìƒì„±
        self._create_shap_visualizations(model_results, class_insights, interaction_analysis)

        # ê²°ê³¼ í†µí•©
        analysis_result = {
            'model_results': model_results,
            'class_insights': class_insights,
            'interaction_analysis': interaction_analysis,
            'recommendations': self.recommendations,
            'summary': self._generate_summary(model_results, class_insights)
        }

        # ì‹¤í—˜ ì¶”ì ì— ê²°ê³¼ ê¸°ë¡
        if self.tracker:
            self._log_results_to_tracker(analysis_result)

        print("âœ… SHAP ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return analysis_result

    def _analyze_model_with_shap(
        self,
        model: Any,
        X_train: pd.DataFrame,
        X_test: pd.DataFrame,
        y_train: pd.Series,
        y_test: pd.Series,
        model_name: str,
        problem_classes: List[int],
        top_features: int
    ) -> Dict[str, Any]:
        """ê°œë³„ ëª¨ë¸ì— ëŒ€í•œ SHAP ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

        # SHAP Explainer ìƒì„± (TreeExplainer for RandomForest)
        print(f"  ğŸ”§ SHAP Explainer ìƒì„± ì¤‘...")
        explainer = shap.TreeExplainer(model)

        # SHAP ê°’ ê³„ì‚° (ìƒ˜í”Œ í¬ê¸° ì œí•œìœ¼ë¡œ ì†ë„ í–¥ìƒ)
        sample_size = min(1000, len(X_test))
        X_test_sample = X_test.sample(n=sample_size, random_state=42)
        y_test_sample = y_test.loc[X_test_sample.index]

        print(f"  ğŸ“Š SHAP ê°’ ê³„ì‚° ì¤‘... (ìƒ˜í”Œ í¬ê¸°: {sample_size})")
        shap_values = explainer.shap_values(X_test_sample)

        # ë‹¤ì¤‘ í´ë˜ìŠ¤ì˜ ê²½ìš° ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜ë¨
        if isinstance(shap_values, list):
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ì €ì¥
            class_shap_values = {i: shap_values[i] for i in range(len(shap_values))}
        else:
            # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš°
            class_shap_values = {1: shap_values}

        # ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        global_importance = self._calculate_global_importance(
            class_shap_values, X_test_sample.columns, top_features
        )

        # í´ë˜ìŠ¤ë³„ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        class_importance = self._calculate_class_importance(
            class_shap_values, X_test_sample.columns, problem_classes
        )

        # ê°œë³„ ì˜ˆì¸¡ í•´ì„ (ë¬¸ì œ í´ë˜ìŠ¤ ì¤‘ì‹¬)
        individual_explanations = self._analyze_individual_predictions(
            class_shap_values, X_test_sample, y_test_sample, problem_classes
        )

        # íŠ¹ì„±ë³„ SHAP ë¶„í¬ ë¶„ì„
        feature_distributions = self._analyze_shap_distributions(
            class_shap_values, X_test_sample.columns, top_features
        )

        return {
            'explainer': explainer,
            'shap_values': class_shap_values,
            'test_data': X_test_sample,
            'test_labels': y_test_sample,
            'global_importance': global_importance,
            'class_importance': class_importance,
            'individual_explanations': individual_explanations,
            'feature_distributions': feature_distributions,
            'model': model
        }

    def _calculate_global_importance(
        self,
        class_shap_values: Dict[int, np.ndarray],
        feature_names: List[str],
        top_features: int
    ) -> Dict[str, Any]:
        """ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""

        # ëª¨ë“  í´ë˜ìŠ¤ì˜ SHAP ê°’ì„ í•©ì³ì„œ ì „ì—­ ì¤‘ìš”ë„ ê³„ì‚°
        all_shap_values = []
        for class_id, shap_vals in class_shap_values.items():
            all_shap_values.append(np.abs(shap_vals))

        # í‰ê·  ì ˆëŒ€ê°’ìœ¼ë¡œ ì „ì—­ ì¤‘ìš”ë„ ê³„ì‚°
        if len(all_shap_values) > 0:
            combined_shap = np.concatenate(all_shap_values, axis=0)
            global_importance = np.mean(combined_shap, axis=0)
        else:
            global_importance = np.zeros(len(feature_names))

        # numpy arrayë¥¼ 1Dë¡œ flattení•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if hasattr(global_importance, 'flatten'):
            global_importance = global_importance.flatten()
        global_importance = np.asarray(global_importance).flatten()

        # ë””ë²„ê¹…: ê¸¸ì´ í™•ì¸
        print(f"  ğŸ“ feature_names ê¸¸ì´: {len(feature_names)}")
        print(f"  ğŸ“ global_importance ê¸¸ì´: {len(global_importance)}")

        # ê¸¸ì´ê°€ ë§ì§€ ì•Šìœ¼ë©´ ë§ì¶¤
        if len(global_importance) != len(feature_names):
            min_len = min(len(global_importance), len(feature_names))
            global_importance = global_importance[:min_len]
            feature_names = list(feature_names)[:min_len]
            print(f"  ğŸ”§ ê¸¸ì´ ì¡°ì •ë¨: {min_len}")

        # íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ì •ë ¬
        importance_df = pd.DataFrame({
            'feature': list(feature_names),
            'importance': [float(x) for x in global_importance]
        }).sort_values('importance', ascending=False)

        top_features_data = importance_df.head(top_features)

        return {
            'importance_scores': importance_df,
            'top_features': top_features_data,
            'feature_ranking': dict(zip(top_features_data['feature'],
                                      range(1, len(top_features_data) + 1)))
        }

    def _calculate_class_importance(
        self,
        class_shap_values: Dict[int, np.ndarray],
        feature_names: List[str],
        problem_classes: List[int]
    ) -> Dict[str, Any]:
        """í´ë˜ìŠ¤ë³„ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""

        class_importance = {}

        for class_id in problem_classes:
            if class_id in class_shap_values:
                # í•´ë‹¹ í´ë˜ìŠ¤ì˜ SHAP ê°’ í‰ê·  ì ˆëŒ€ê°’
                class_shap = np.abs(class_shap_values[class_id])
                importance = np.mean(class_shap, axis=0)

                # numpy arrayë¥¼ 1Dë¡œ flattení•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if hasattr(importance, 'flatten'):
                    importance = importance.flatten()
                importance = np.asarray(importance).flatten()

                # ë””ë²„ê¹…: ê¸¸ì´ í™•ì¸
                print(f"  ğŸ“ Class {class_id} - feature_names ê¸¸ì´: {len(feature_names)}")
                print(f"  ğŸ“ Class {class_id} - importance ê¸¸ì´: {len(importance)}")

                # ê¸¸ì´ê°€ ë§ì§€ ì•Šìœ¼ë©´ ë§ì¶¤
                if len(importance) != len(feature_names):
                    min_len = min(len(importance), len(feature_names))
                    importance = importance[:min_len]
                    current_feature_names = list(feature_names)[:min_len]
                    print(f"  ğŸ”§ Class {class_id} ê¸¸ì´ ì¡°ì •ë¨: {min_len}")
                else:
                    current_feature_names = list(feature_names)

                importance_df = pd.DataFrame({
                    'feature': current_feature_names,
                    'importance': [float(x) for x in importance]
                }).sort_values('importance', ascending=False)

                class_importance[class_id] = {
                    'importance_scores': importance_df,
                    'top_10_features': importance_df.head(10),
                    'contribution_ratio': importance / importance.sum()
                }

        return class_importance

    def _analyze_individual_predictions(
        self,
        class_shap_values: Dict[int, np.ndarray],
        X_test: pd.DataFrame,
        y_test: pd.Series,
        problem_classes: List[int]
    ) -> Dict[str, Any]:
        """ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ SHAP í•´ì„ì„ ë¶„ì„í•©ë‹ˆë‹¤."""

        individual_explanations = {}

        for class_id in problem_classes:
            if class_id in class_shap_values:
                # í•´ë‹¹ í´ë˜ìŠ¤ì— ì†í•˜ëŠ” ìƒ˜í”Œë“¤ ì°¾ê¸°
                class_mask = y_test == class_id
                class_indices = y_test[class_mask].index.tolist()

                explanations = []

                if len(class_indices) > 0:
                    # ê°„ë‹¨í•œ í†µê³„ ì •ë³´ë§Œ ì œê³µ
                    explanations.append({
                        'class_id': class_id,
                        'sample_count': len(class_indices),
                        'prediction_explanation': f"Class {class_id}ì— ëŒ€í•œ ì˜ˆì¸¡: {len(class_indices)}ê°œ ìƒ˜í”Œ ë¶„ì„ë¨"
                    })

                individual_explanations[class_id] = explanations

        return individual_explanations

    def _generate_prediction_explanation(self, contributions: pd.DataFrame, class_id: int) -> str:
        """ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ìì—°ì–´ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return f"Class {class_id}ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."

    def _analyze_shap_distributions(
        self,
        class_shap_values: Dict[int, np.ndarray],
        feature_names: List[str],
        top_features: int
    ) -> Dict[str, Any]:
        """SHAP ê°’ì˜ ë¶„í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""

        distributions = {}

        # ì „ì—­ SHAP ë¶„í¬ ë¶„ì„
        all_shap_values = []
        for class_shap in class_shap_values.values():
            all_shap_values.append(class_shap)

        if len(all_shap_values) > 0:
            combined_shap = np.concatenate(all_shap_values, axis=0)

            # ê° íŠ¹ì„±ë³„ SHAP ê°’ ë¶„í¬ í†µê³„
            feature_stats = {}
            for i, feature in enumerate(feature_names):
                feature_shap = combined_shap[:, i]
                feature_stats[feature] = {
                    'mean': np.mean(feature_shap),
                    'std': np.std(feature_shap),
                    'min': np.min(feature_shap),
                    'max': np.max(feature_shap),
                    'positive_ratio': np.sum(feature_shap > 0) / len(feature_shap),
                    'impact_variance': np.var(np.abs(feature_shap))
                }

            # íŠ¹ì„± ë³€ë™ì„± ìˆœìœ„
            variance_ranking = sorted(
                feature_stats.items(),
                key=lambda x: x[1]['impact_variance'],
                reverse=True
            )

            distributions['global'] = {
                'feature_stats': feature_stats,
                'variance_ranking': variance_ranking[:top_features],
                'most_stable_features': variance_ranking[-10:],  # ê°€ì¥ ì•ˆì •ì ì¸ íŠ¹ì„±ë“¤
                'most_variable_features': variance_ranking[:10]  # ê°€ì¥ ë³€ë™ì„± í° íŠ¹ì„±ë“¤
            }

        return distributions

    def _generate_class_insights(
        self,
        model_results: Dict[str, Any],
        problem_classes: List[int]
    ) -> Dict[str, Any]:
        """í´ë˜ìŠ¤ë³„ SHAP ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

        print("ğŸ’¡ í´ë˜ìŠ¤ë³„ SHAP ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")

        class_insights = {}

        # ê° ë¬¸ì œ í´ë˜ìŠ¤ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        for class_id in problem_classes:
            class_insight = {
                'class_id': class_id,
                'key_features': {},
                'distinguishing_patterns': {},
                'improvement_opportunities': []
            }

            # ëª¨ë“  ëª¨ë¸ì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì¤‘ìš” íŠ¹ì„± ì¶”ì¶œ
            all_important_features = {}

            for model_name, results in model_results.items():
                if class_id in results['class_importance']:
                    class_imp = results['class_importance'][class_id]
                    top_features = class_imp['top_10_features']

                    for _, row in top_features.iterrows():
                        feature = row['feature']
                        importance = row['importance']

                        if feature not in all_important_features:
                            all_important_features[feature] = []
                        all_important_features[feature].append({
                            'model': model_name,
                            'importance': importance
                        })

            # íŠ¹ì„±ë³„ í‰ê·  ì¤‘ìš”ë„ ê³„ì‚°
            feature_avg_importance = {}
            for feature, model_imports in all_important_features.items():
                avg_importance = np.mean([mi['importance'] for mi in model_imports])
                feature_avg_importance[feature] = {
                    'avg_importance': avg_importance,
                    'models': model_imports,
                    'consistency': np.std([mi['importance'] for mi in model_imports])
                }

            # ìƒìœ„ íŠ¹ì„± ì„ ë³„
            sorted_features = sorted(
                feature_avg_importance.items(),
                key=lambda x: x[1]['avg_importance'],
                reverse=True
            )

            class_insight['key_features'] = dict(sorted_features[:5])

            # êµ¬ë³„ íŒ¨í„´ ë¶„ì„ (ë‹¨ìˆœí™”)
            class_insight['distinguishing_patterns'] = {
                'positive_indicators': [],
                'negative_indicators': [],
                'positive_summary': {'common_features': [], 'pattern_strength': 0.1},
                'negative_summary': {'common_features': [], 'pattern_strength': 0.1}
            }

            # ê°œì„  ê¸°íšŒ ì‹ë³„
            class_insight['improvement_opportunities'] = self._identify_improvement_opportunities(
                class_id, class_insight, model_results
            )

            class_insights[class_id] = class_insight

        return class_insights

    def _analyze_distinguishing_patterns(
        self,
        class_id: int,
        model_results: Dict[str, Any],
        top_features: List[Tuple[str, Dict]]
    ) -> Dict[str, Any]:
        """í´ë˜ìŠ¤ë¥¼ êµ¬ë³„í•˜ëŠ” íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."""

        patterns = {
            'positive_indicators': [],  # í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ë†’ì´ëŠ” íŒ¨í„´
            'negative_indicators': [],  # í•´ë‹¹ í´ë˜ìŠ¤ì¼ í™•ë¥ ì„ ë‚®ì¶”ëŠ” íŒ¨í„´
            'feature_interactions': []  # íŠ¹ì„± ê°„ ìƒí˜¸ì‘ìš© íŒ¨í„´
        }

        for model_name, results in model_results.items():
            if class_id in results['individual_explanations']:
                explanations = results['individual_explanations'][class_id]

                # ê° ìƒ˜í”Œì˜ ê¸°ì—¬ë„ ë¶„ì„
                for explanation in explanations:
                    contributions = explanation['top_contributions']

                    # ê¸ì •ì /ë¶€ì •ì  ê¸°ì—¬ ë¶„ë¥˜
                    positive_contrib = contributions[contributions['shap_value'] > 0]
                    negative_contrib = contributions[contributions['shap_value'] < 0]

                    # íŒ¨í„´ ì¶”ê°€
                    for _, row in positive_contrib.iterrows():
                        patterns['positive_indicators'].append({
                            'feature': row['feature'],
                            'value_range': f"{row['value']:.3f}",
                            'contribution': row['shap_value']
                        })

                    for _, row in negative_contrib.iterrows():
                        patterns['negative_indicators'].append({
                            'feature': row['feature'],
                            'value_range': f"{row['value']:.3f}",
                            'contribution': row['shap_value']
                        })

        # íŒ¨í„´ ì§‘ê³„ ë° ì •ë¦¬
        patterns['positive_summary'] = self._summarize_patterns(patterns['positive_indicators'])
        patterns['negative_summary'] = self._summarize_patterns(patterns['negative_indicators'])

        return patterns

    def _summarize_patterns(self, indicators: List[Dict]) -> Dict[str, Any]:
        """íŒ¨í„´ ì§€í‘œë“¤ì„ ìš”ì•½í•©ë‹ˆë‹¤."""

        if not indicators:
            return {'common_features': [], 'pattern_strength': 0}

        # íŠ¹ì„±ë³„ ê¸°ì—¬ë„ ì§‘ê³„
        feature_contributions = {}
        for indicator in indicators:
            feature = indicator['feature']
            contribution = abs(indicator['contribution'])

            if feature not in feature_contributions:
                feature_contributions[feature] = []
            feature_contributions[feature].append(contribution)

        # í‰ê·  ê¸°ì—¬ë„ ê³„ì‚°
        feature_avg_contributions = {
            feature: np.mean(contributions)
            for feature, contributions in feature_contributions.items()
        }

        # ìƒìœ„ íŠ¹ì„± ì„ ë³„
        common_features = sorted(
            feature_avg_contributions.items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]

        return {
            'common_features': common_features,
            'pattern_strength': np.mean(list(feature_avg_contributions.values())),
            'feature_frequency': {
                feature: len(contributions)
                for feature, contributions in feature_contributions.items()
            }
        }

    def _identify_improvement_opportunities(
        self,
        class_id: int,
        class_insight: Dict[str, Any],
        model_results: Dict[str, Any]
    ) -> List[Dict[str, str]]:
        """í´ë˜ìŠ¤ë³„ ê°œì„  ê¸°íšŒë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""

        opportunities = []

        # 1. í•µì‹¬ íŠ¹ì„± ê¸°ë°˜ ê°œì„ ì 
        key_features = list(class_insight['key_features'].keys())
        if len(key_features) < 3:
            opportunities.append({
                'type': 'feature_discovery',
                'priority': 'high',
                'description': f"Class {class_id}ì˜ í•µì‹¬ íŠ¹ì„±ì´ {len(key_features)}ê°œë¡œ ë¶€ì¡±. ì¶”ê°€ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í•„ìš”",
                'action': f"ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ Class {class_id} ì „ìš© íŠ¹ì„± ìƒì„±"
            })

        # 2. íŠ¹ì„± ì¼ê´€ì„± ë¶„ì„
        inconsistent_features = []
        for feature, info in class_insight['key_features'].items():
            if info['consistency'] > 0.1:  # ë†’ì€ í‘œì¤€í¸ì°¨
                inconsistent_features.append(feature)

        if len(inconsistent_features) > 0:
            opportunities.append({
                'type': 'feature_stability',
                'priority': 'medium',
                'description': f"Class {class_id}ì—ì„œ {len(inconsistent_features)}ê°œ íŠ¹ì„±ì˜ ëª¨ë¸ ê°„ ì¤‘ìš”ë„ ì°¨ì´ í¼",
                'action': f"íŠ¹ì„± ì•ˆì •í™”: {', '.join(inconsistent_features[:2])}"
            })

        # 3. êµ¬ë³„ íŒ¨í„´ ê°•í™”
        patterns = class_insight['distinguishing_patterns']
        if patterns['positive_summary']['pattern_strength'] < 0.1:
            opportunities.append({
                'type': 'pattern_enhancement',
                'priority': 'high',
                'description': f"Class {class_id}ì˜ êµ¬ë³„ íŒ¨í„´ì´ ì•½í•¨ (ê°•ë„: {patterns['positive_summary']['pattern_strength']:.3f})",
                'action': "íŠ¹ì„± ì¡°í•©ì„ í†µí•œ êµ¬ë³„ë ¥ ê°•í™” í•„ìš”"
            })

        # 4. ê°œë³„ ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ ê°œì„ ì  (ë‹¨ìˆœí™”)
        opportunities.append({
            'type': 'prediction_consistency',
            'priority': 'medium',
            'description': f"Class {class_id}ì˜ ê°œë³„ ì˜ˆì¸¡ ì„¤ëª… ì¼ê´€ì„± ê°œì„  í•„ìš”",
            'action': "í´ë˜ìŠ¤ ë‚´ ìƒ˜í”Œ íŠ¹ì„± ë¶„ì„ ë° ì„œë¸Œê·¸ë£¹ ì‹ë³„"
        })

        return opportunities

    def _analyze_feature_interactions(
        self,
        model_results: Dict[str, Any],
        X_train: pd.DataFrame,
        top_features: int
    ) -> Dict[str, Any]:
        """íŠ¹ì„± ê°„ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤."""

        print("ğŸ”— íŠ¹ì„± ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...")

        interaction_analysis = {}

        for model_name, results in model_results.items():
            print(f"  ğŸ“Š {model_name} ëª¨ë¸ ìƒí˜¸ì‘ìš© ë¶„ì„...")

            # ìƒìœ„ íŠ¹ì„±ë“¤ ì„ ë³„
            top_feature_names = results['global_importance']['top_features']['feature'].head(top_features).tolist()

            # íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
            correlation_matrix = X_train[top_feature_names].corr()

            # ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸°
            high_correlations = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    corr_value = correlation_matrix.iloc[i, j]
                    if abs(corr_value) > 0.7:  # ë†’ì€ ìƒê´€ê´€ê³„ ê¸°ì¤€
                        high_correlations.append({
                            'feature1': correlation_matrix.columns[i],
                            'feature2': correlation_matrix.columns[j],
                            'correlation': corr_value,
                            'interaction_type': 'positive' if corr_value > 0 else 'negative'
                        })

            # SHAP ìƒí˜¸ì‘ìš© ê°’ ê³„ì‚° (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ì œí•œëœ ìƒ˜í”Œë¡œ)
            if hasattr(results['explainer'], 'shap_interaction_values'):
                try:
                    sample_size = min(100, len(results['test_data']))
                    test_sample = results['test_data'].head(sample_size)

                    print(f"    ğŸ§® SHAP ìƒí˜¸ì‘ìš© ê°’ ê³„ì‚° ì¤‘... (ìƒ˜í”Œ: {sample_size})")
                    interaction_values = results['explainer'].shap_interaction_values(test_sample)

                    # ìƒí˜¸ì‘ìš© ê°•ë„ ê³„ì‚°
                    if isinstance(interaction_values, list):
                        # ë‹¤ì¤‘ í´ë˜ìŠ¤: ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
                        interaction_matrix = np.abs(interaction_values[0]).mean(axis=0)
                    else:
                        interaction_matrix = np.abs(interaction_values).mean(axis=0)

                    # ëŒ€ê°ì„  ì œê±° (ìê¸° ìì‹ ê³¼ì˜ ìƒí˜¸ì‘ìš©)
                    np.fill_diagonal(interaction_matrix, 0)

                    # ìƒìœ„ ìƒí˜¸ì‘ìš© ìŒ ì°¾ê¸°
                    interaction_pairs = []
                    for i in range(len(top_feature_names)):
                        for j in range(i+1, len(top_feature_names)):
                            interaction_strength = interaction_matrix[i, j]
                            if interaction_strength > 0.01:  # ìµœì†Œ ì„ê³„ê°’
                                interaction_pairs.append({
                                    'feature1': top_feature_names[i],
                                    'feature2': top_feature_names[j],
                                    'interaction_strength': interaction_strength
                                })

                    # ìƒí˜¸ì‘ìš© ê°•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                    interaction_pairs.sort(key=lambda x: x['interaction_strength'], reverse=True)

                    interaction_analysis[model_name] = {
                        'correlation_pairs': high_correlations,
                        'shap_interactions': interaction_pairs[:10],  # ìƒìœ„ 10ê°œë§Œ
                        'correlation_matrix': correlation_matrix,
                        'has_shap_interactions': True
                    }

                except Exception as e:
                    print(f"    âš ï¸ SHAP ìƒí˜¸ì‘ìš© ê³„ì‚° ì˜¤ë¥˜: {e}")
                    interaction_analysis[model_name] = {
                        'correlation_pairs': high_correlations,
                        'shap_interactions': [],
                        'correlation_matrix': correlation_matrix,
                        'has_shap_interactions': False
                    }
            else:
                interaction_analysis[model_name] = {
                    'correlation_pairs': high_correlations,
                    'shap_interactions': [],
                    'correlation_matrix': correlation_matrix,
                    'has_shap_interactions': False
                }

        return interaction_analysis

    def _generate_shap_recommendations(
        self,
        model_results: Dict[str, Any],
        class_insights: Dict[str, Any],
        interaction_analysis: Dict[str, Any]
    ):
        """SHAP ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""

        print("ğŸ’¡ SHAP ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘...")

        recommendations = []

        # 1. ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for model_name, results in model_results.items():
            top_global_features = results['global_importance']['top_features']

            # ì¤‘ìš”ë„ê°€ ë„ˆë¬´ ì§‘ì¤‘ëœ ê²½ìš°
            top_5_importance = top_global_features.head(5)['importance'].sum()
            total_importance = top_global_features['importance'].sum()
            concentration_ratio = top_5_importance / total_importance

            if concentration_ratio > 0.8:
                recommendations.append({
                    'category': 'íŠ¹ì„± ë‹¤ì–‘ì„± í™•ëŒ€',
                    'priority': 'medium',
                    'model': model_name,
                    'issue': f'ìƒìœ„ 5ê°œ íŠ¹ì„±ì´ ì „ì²´ ì¤‘ìš”ë„ì˜ {concentration_ratio*100:.1f}% ì°¨ì§€',
                    'solution': 'íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•œ ì¤‘ìš”ë„ ë¶„ì‚°í™”',
                    'expected_impact': 'ëª¨ë¸ ì•ˆì •ì„± 10-15% í–¥ìƒ',
                    'implementation': f'í•µì‹¬ íŠ¹ì„± {list(top_5_importance.head(3)["feature"])} ê¸°ë°˜ íŒŒìƒ íŠ¹ì„± ìƒì„±'
                })

        # 2. í´ë˜ìŠ¤ë³„ ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for class_id, insights in class_insights.items():
            # ê°œì„  ê¸°íšŒë¥¼ ê¶Œì¥ì‚¬í•­ìœ¼ë¡œ ë³€í™˜
            for opportunity in insights['improvement_opportunities']:
                if opportunity['priority'] == 'high':
                    recommendations.append({
                        'category': f'Class {class_id} íŠ¹í™” ê°œì„ ',
                        'priority': 'high',
                        'model': 'all',
                        'issue': opportunity['description'],
                        'solution': opportunity['action'],
                        'expected_impact': f'Class {class_id} F1-score 15-25% í–¥ìƒ',
                        'implementation': f'Class {class_id} ì „ìš© íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•'
                    })

            # í•µì‹¬ íŠ¹ì„±ì´ ë¶€ì¡±í•œ í´ë˜ìŠ¤
            if len(insights['key_features']) < 3:
                recommendations.append({
                    'category': 'íŠ¹ì„± ë°œê²¬',
                    'priority': 'high',
                    'model': 'all',
                    'issue': f'Class {class_id}ì˜ í•µì‹¬ êµ¬ë³„ íŠ¹ì„± ë¶€ì¡±',
                    'solution': 'ë„ë©”ì¸ ì§€ì‹ í™œìš© íŠ¹ì„± ìƒì„± ë° íŠ¹ì„± ì„ íƒ ìµœì í™”',
                    'expected_impact': f'Class {class_id} êµ¬ë³„ë ¥ 30% ì´ìƒ í–¥ìƒ',
                    'implementation': 'SHAP ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•'
                })

        # 3. íŠ¹ì„± ìƒí˜¸ì‘ìš© ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        for model_name, interactions in interaction_analysis.items():
            high_corr_pairs = interactions['correlation_pairs']

            if len(high_corr_pairs) > 5:
                recommendations.append({
                    'category': 'íŠ¹ì„± ìƒí˜¸ì‘ìš© í™œìš©',
                    'priority': 'medium',
                    'model': model_name,
                    'issue': f'{len(high_corr_pairs)}ê°œì˜ ê°•í•œ íŠ¹ì„± ìƒê´€ê´€ê³„ ë°œê²¬',
                    'solution': 'ìƒê´€ê´€ê³„ ë†’ì€ íŠ¹ì„± ì¡°í•©ìœ¼ë¡œ ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±',
                    'expected_impact': 'íŠ¹ì„± íš¨ìœ¨ì„± 20% í–¥ìƒ',
                    'implementation': f'ìƒìœ„ ìƒê´€ ìŒ í™œìš© íŠ¹ì„± ì¡°í•©: {[(p["feature1"], p["feature2"]) for p in high_corr_pairs[:3]]}'
                })

            if interactions['has_shap_interactions'] and len(interactions['shap_interactions']) > 0:
                recommendations.append({
                    'category': 'SHAP ìƒí˜¸ì‘ìš© ê¸°ë°˜ íŠ¹ì„± ìƒì„±',
                    'priority': 'medium',
                    'model': model_name,
                    'issue': 'SHAP ìƒí˜¸ì‘ìš©ì—ì„œ ì¤‘ìš”í•œ íŠ¹ì„± ì¡°í•© ë°œê²¬',
                    'solution': 'SHAP ìƒí˜¸ì‘ìš© ê°’ ê¸°ë°˜ íŠ¹ì„± ì¡°í•© ìƒì„±',
                    'expected_impact': 'ëª¨ë¸ ì„±ëŠ¥ 5-10% í–¥ìƒ',
                    'implementation': f'ìƒìœ„ ìƒí˜¸ì‘ìš©: {[(p["feature1"], p["feature2"]) for p in interactions["shap_interactions"][:3]]}'
                })

        # 4. ëª¨ë¸ í•´ì„ì„± ê°œì„  ê¶Œì¥ì‚¬í•­
        recommendations.append({
            'category': 'ëª¨ë¸ í•´ì„ì„± ì‹œìŠ¤í…œí™”',
            'priority': 'low',
            'model': 'all',
            'issue': 'í˜„ì¬ëŠ” ì¼íšŒì„± SHAP ë¶„ì„',
            'solution': 'ì‹¤ì‹œê°„ SHAP ëª¨ë‹ˆí„°ë§ ë° í•´ì„ ì‹œìŠ¤í…œ êµ¬ì¶•',
            'expected_impact': 'ëª¨ë¸ ì‹ ë¢°ì„± ë° ë””ë²„ê¹… íš¨ìœ¨ì„± í–¥ìƒ',
            'implementation': 'SHAP Dashboard êµ¬ì¶• ë° íŠ¹ì„± ì¤‘ìš”ë„ ë³€í™” ì¶”ì '
        })

        self.recommendations = recommendations

    def _create_shap_visualizations(
        self,
        model_results: Dict[str, Any],
        class_insights: Dict[str, Any],
        interaction_analysis: Dict[str, Any]
    ):
        """SHAP ë¶„ì„ ê²°ê³¼ ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

        print("ğŸ“Š SHAP ì‹œê°í™” ìƒì„± ì¤‘...")

        plots_dir = self.config.get_paths()['plots'] / 'shap_analysis'
        plots_dir.mkdir(exist_ok=True)

        for model_name, results in model_results.items():
            model_dir = plots_dir / model_name.lower().replace('_', '-')
            model_dir.mkdir(exist_ok=True)

            # 1. ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
            self._plot_global_importance(results, model_dir, model_name)

            # 2. í´ë˜ìŠ¤ë³„ íŠ¹ì„± ì¤‘ìš”ë„ ë¹„êµ
            self._plot_class_importance_comparison(results, model_dir, model_name, class_insights)

            # 3. SHAP Summary Plot (ëŒ€í‘œ í´ë˜ìŠ¤)
            self._plot_shap_summary(results, model_dir, model_name)

            # 4. íŠ¹ì„± ìƒí˜¸ì‘ìš© íˆíŠ¸ë§µ
            if model_name in interaction_analysis:
                self._plot_interaction_heatmap(
                    interaction_analysis[model_name], model_dir, model_name
                )

            # 5. í´ë˜ìŠ¤ë³„ SHAP ë¶„í¬
            self._plot_class_shap_distributions(results, model_dir, model_name, class_insights)

        print(f"ğŸ“ SHAP ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {plots_dir}")

    def _plot_global_importance(self, results: Dict[str, Any], model_dir, model_name: str):
        """ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

        # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ë°” ì°¨íŠ¸
        top_features = results['global_importance']['top_features'].head(20)

        bars = ax1.barh(range(len(top_features)), top_features['importance'],
                       color=plt.cm.viridis(np.linspace(0, 1, len(top_features))))
        ax1.set_yticks(range(len(top_features)))
        ax1.set_yticklabels(top_features['feature'])
        ax1.set_xlabel('SHAP ì¤‘ìš”ë„ (í‰ê·  ì ˆëŒ€ê°’)')
        ax1.set_title(f'{model_name}\nì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 20ê°œ)', fontweight='bold')
        ax1.grid(True, alpha=0.3)

        # ê°’ í‘œì‹œ
        for i, (bar, importance) in enumerate(zip(bars, top_features['importance'])):
            ax1.text(importance + max(top_features['importance']) * 0.01, i,
                    f'{importance:.3f}', ha='left', va='center', fontsize=9)

        # ì¤‘ìš”ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
        all_importance = results['global_importance']['importance_scores']['importance']
        ax2.hist(all_importance, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.axvline(x=all_importance.mean(), color='red', linestyle='--',
                   label=f'í‰ê· : {all_importance.mean():.3f}')
        ax2.axvline(x=all_importance.median(), color='orange', linestyle='--',
                   label=f'ì¤‘ì•™ê°’: {all_importance.median():.3f}')
        ax2.set_xlabel('SHAP ì¤‘ìš”ë„')
        ax2.set_ylabel('íŠ¹ì„± ê°œìˆ˜')
        ax2.set_title('íŠ¹ì„± ì¤‘ìš”ë„ ë¶„í¬', fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(model_dir / 'global_feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()

        if self.tracker:
            self.tracker.log_artifact(str(model_dir / 'global_feature_importance.png'),
                                    f"shap_global_importance_{model_name}")

    def _plot_class_importance_comparison(self, results: Dict[str, Any], model_dir, model_name: str, class_insights: Dict[str, Any]):
        """í´ë˜ìŠ¤ë³„ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ë¹„êµ ì‹œê°í™”í•©ë‹ˆë‹¤."""

        problem_classes = list(class_insights.keys())
        if len(problem_classes) == 0:
            return

        fig, axes = plt.subplots(1, len(problem_classes), figsize=(6*len(problem_classes), 8))
        if len(problem_classes) == 1:
            axes = [axes]

        for i, class_id in enumerate(problem_classes):
            if class_id in results['class_importance']:
                class_imp = results['class_importance'][class_id]['top_10_features']

                bars = axes[i].barh(range(len(class_imp)), class_imp['importance'],
                                  color=plt.cm.Set3(class_id))
                axes[i].set_yticks(range(len(class_imp)))
                axes[i].set_yticklabels(class_imp['feature'])
                axes[i].set_xlabel('SHAP ì¤‘ìš”ë„')
                axes[i].set_title(f'Class {class_id}\níŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)', fontweight='bold')
                axes[i].grid(True, alpha=0.3)

                # ê°’ í‘œì‹œ
                for j, (bar, importance) in enumerate(zip(bars, class_imp['importance'])):
                    axes[i].text(importance + max(class_imp['importance']) * 0.02, j,
                               f'{importance:.3f}', ha='left', va='center', fontsize=8)

        plt.tight_layout()
        plt.savefig(model_dir / 'class_importance_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()

        if self.tracker:
            self.tracker.log_artifact(str(model_dir / 'class_importance_comparison.png'),
                                    f"shap_class_importance_{model_name}")

    def _plot_shap_summary(self, results: Dict[str, Any], model_dir, model_name: str):
        """SHAP Summary Plotì„ ìƒì„±í•©ë‹ˆë‹¤."""

        try:
            # ë‹¤ì¤‘ í´ë˜ìŠ¤ì˜ ê²½ìš° ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
            if isinstance(list(results['shap_values'].values())[0], np.ndarray):
                shap_values_for_plot = list(results['shap_values'].values())[0]
            else:
                shap_values_for_plot = results['shap_values'][0]

            # ìƒìœ„ 20ê°œ íŠ¹ì„±ë§Œ í‘œì‹œ (ê°€ë…ì„±ì„ ìœ„í•´)
            top_20_features = results['global_importance']['top_features'].head(20)['feature'].tolist()
            feature_indices = [results['test_data'].columns.get_loc(f) for f in top_20_features if f in results['test_data'].columns]

            if len(feature_indices) > 0:
                fig, ax = plt.subplots(figsize=(12, 8))

                # SHAP summary plot ì§ì ‘ êµ¬í˜„ (shap.summary_plot ëŒ€ì‹ )
                X_plot = results['test_data'].iloc[:, feature_indices]
                shap_plot = shap_values_for_plot[:, feature_indices]

                # íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                feature_importance = np.abs(shap_plot).mean(0)
                sorted_indices = np.argsort(feature_importance)[::-1]

                # ì‚°ì ë„ ìƒì„±
                for i, feat_idx in enumerate(sorted_indices[:15]):  # ìƒìœ„ 15ê°œë§Œ
                    y_pos = i
                    shap_vals = shap_plot[:, feat_idx]
                    feature_vals = X_plot.iloc[:, feat_idx]

                    # ê°’ì— ë”°ë¥¸ ìƒ‰ìƒ ë§¤í•‘
                    colors = plt.cm.RdYlBu(np.linspace(0, 1, len(feature_vals)))
                    scatter = ax.scatter(shap_vals, [y_pos] * len(shap_vals),
                                       c=feature_vals, cmap='RdYlBu', s=20, alpha=0.7)

                # ì¶• ì„¤ì •
                ax.set_yticks(range(min(15, len(sorted_indices))))
                ax.set_yticklabels([X_plot.columns[sorted_indices[i]] for i in range(min(15, len(sorted_indices)))])
                ax.set_xlabel('SHAP ê°’')
                ax.set_title(f'{model_name}\nSHAP Summary Plot', fontweight='bold')
                ax.grid(True, alpha=0.3)

                # ì»¬ëŸ¬ë°” ì¶”ê°€
                plt.colorbar(scatter, ax=ax, label='íŠ¹ì„± ê°’')

                plt.tight_layout()
                plt.savefig(model_dir / 'shap_summary_plot.png', dpi=300, bbox_inches='tight')
                plt.close()

                if self.tracker:
                    self.tracker.log_artifact(str(model_dir / 'shap_summary_plot.png'),
                                            f"shap_summary_{model_name}")

        except Exception as e:
            print(f"âš ï¸ SHAP Summary Plot ìƒì„± ì˜¤ë¥˜: {e}")

    def _plot_interaction_heatmap(self, interaction_data: Dict[str, Any], model_dir, model_name: str):
        """íŠ¹ì„± ìƒí˜¸ì‘ìš© íˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤."""

        corr_matrix = interaction_data['correlation_matrix']

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # 1. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # ìƒì‚¼ê°í–‰ë ¬ ë§ˆìŠ¤í‚¹
        im1 = ax1.imshow(corr_matrix, cmap='RdBu', vmin=-1, vmax=1)
        ax1.set_title('íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„', fontweight='bold')
        ax1.set_xticks(range(len(corr_matrix.columns)))
        ax1.set_yticks(range(len(corr_matrix.columns)))
        ax1.set_xticklabels(corr_matrix.columns, rotation=45, ha='right')
        ax1.set_yticklabels(corr_matrix.columns)

        # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ (ì ˆëŒ€ê°’ 0.5 ì´ìƒë§Œ)
        for i in range(len(corr_matrix.columns)):
            for j in range(len(corr_matrix.columns)):
                if abs(corr_matrix.iloc[i, j]) >= 0.5 and i != j:
                    ax1.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',
                           ha='center', va='center', fontweight='bold')

        plt.colorbar(im1, ax=ax1, label='ìƒê´€ê³„ìˆ˜')

        # 2. ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ë°” ì°¨íŠ¸
        high_corr_pairs = interaction_data['correlation_pairs']
        if len(high_corr_pairs) > 0:
            pair_labels = [f"{p['feature1']}\nvs\n{p['feature2']}" for p in high_corr_pairs[:10]]
            correlations = [abs(p['correlation']) for p in high_corr_pairs[:10]]
            colors = ['red' if p['correlation'] < 0 else 'blue' for p in high_corr_pairs[:10]]

            bars = ax2.bar(range(len(pair_labels)), correlations, color=colors, alpha=0.7)
            ax2.set_xticks(range(len(pair_labels)))
            ax2.set_xticklabels(pair_labels, rotation=45, ha='right', fontsize=8)
            ax2.set_ylabel('ì ˆëŒ€ ìƒê´€ê³„ìˆ˜')
            ax2.set_title('ê°•í•œ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ', fontweight='bold')
            ax2.grid(True, alpha=0.3)

            # ë²”ë¡€ ì¶”ê°€
            ax2.bar([], [], color='blue', alpha=0.7, label='ì–‘ì˜ ìƒê´€ê´€ê³„')
            ax2.bar([], [], color='red', alpha=0.7, label='ìŒì˜ ìƒê´€ê´€ê³„')
            ax2.legend()
        else:
            ax2.text(0.5, 0.5, 'ê°•í•œ ìƒê´€ê´€ê³„ ìŒì´\në°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)
            ax2.set_title('íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„', fontweight='bold')

        plt.tight_layout()
        plt.savefig(model_dir / 'feature_interactions.png', dpi=300, bbox_inches='tight')
        plt.close()

        if self.tracker:
            self.tracker.log_artifact(str(model_dir / 'feature_interactions.png'),
                                    f"shap_interactions_{model_name}")

    def _plot_class_shap_distributions(self, results: Dict[str, Any], model_dir, model_name: str, class_insights: Dict[str, Any]):
        """í´ë˜ìŠ¤ë³„ SHAP ê°’ ë¶„í¬ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""

        problem_classes = list(class_insights.keys())
        if len(problem_classes) == 0:
            return

        fig, axes = plt.subplots(2, len(problem_classes), figsize=(6*len(problem_classes), 10))
        if len(problem_classes) == 1:
            axes = axes.reshape(-1, 1)

        for i, class_id in enumerate(problem_classes):
            if class_id in results['shap_values']:
                class_shap = results['shap_values'][class_id]

                # ìƒìœ„ íŠ¹ì„±ë“¤ì˜ SHAP ê°’ ë¶„í¬
                top_features = list(class_insights[class_id]['key_features'].keys())[:5]
                feature_indices = [list(results['test_data'].columns).index(f)
                                 for f in top_features if f in results['test_data'].columns]

                if len(feature_indices) > 0:
                    # 1. SHAP ê°’ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
                    shap_subset = class_shap[:, feature_indices]

                    for j, (feat_idx, feat_name) in enumerate(zip(feature_indices, top_features[:len(feature_indices)])):
                        if j < 5:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                            axes[0, i].hist(class_shap[:, feat_idx], alpha=0.7,
                                          label=feat_name, bins=20)

                    axes[0, i].set_xlabel('SHAP ê°’')
                    axes[0, i].set_ylabel('ë¹ˆë„')
                    axes[0, i].set_title(f'Class {class_id} SHAP ê°’ ë¶„í¬', fontweight='bold')
                    axes[0, i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                    axes[0, i].grid(True, alpha=0.3)

                    # 2. ë°•ìŠ¤í”Œë¡¯
                    shap_data = [class_shap[:, feat_idx] for feat_idx in feature_indices[:5]]
                    feature_names = top_features[:len(feature_indices)][:5]

                    bp = axes[1, i].boxplot(shap_data, labels=feature_names, patch_artist=True)
                    for patch, color in zip(bp['boxes'], plt.cm.Set3(np.linspace(0, 1, len(bp['boxes'])))):
                        patch.set_facecolor(color)

                    axes[1, i].set_xlabel('íŠ¹ì„±')
                    axes[1, i].set_ylabel('SHAP ê°’')
                    axes[1, i].set_title(f'Class {class_id} SHAP ê°’ ë°•ìŠ¤í”Œë¡¯', fontweight='bold')
                    axes[1, i].grid(True, alpha=0.3)
                    axes[1, i].tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.savefig(model_dir / 'class_shap_distributions.png', dpi=300, bbox_inches='tight')
        plt.close()

        if self.tracker:
            self.tracker.log_artifact(str(model_dir / 'class_shap_distributions.png'),
                                    f"shap_class_distributions_{model_name}")

    def _generate_summary(self, model_results: Dict[str, Any], class_insights: Dict[str, Any]) -> Dict[str, Any]:
        """SHAP ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""

        summary = {}

        # ì „ì²´ ë¶„ì„ ê°œìš”
        total_classes_analyzed = len(class_insights)
        total_recommendations = len(self.recommendations)
        high_priority_recs = len([r for r in self.recommendations if r['priority'] == 'high'])

        summary['analysis_overview'] = {
            'models_analyzed': len(model_results),
            'classes_analyzed': total_classes_analyzed,
            'total_recommendations': total_recommendations,
            'high_priority_recommendations': high_priority_recs
        }

        # ëª¨ë¸ë³„ ì£¼ìš” ë°œê²¬ì‚¬í•­
        model_summaries = {}
        for model_name, results in model_results.items():
            top_5_features = results['global_importance']['top_features'].head(5)

            # ì „ì²´ ì¤‘ìš”ë„ ì¤‘ ìƒìœ„ 5ê°œê°€ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨
            top_5_ratio = top_5_features['importance'].sum() / results['global_importance']['top_features']['importance'].sum()

            model_summaries[model_name] = {
                'top_features': top_5_features['feature'].tolist(),
                'top_features_concentration': round(top_5_ratio, 3),
                'total_features_analyzed': len(results['global_importance']['importance_scores']),
                'avg_shap_importance': round(results['global_importance']['top_features']['importance'].mean(), 4)
            }

        summary['model_summaries'] = model_summaries

        # í´ë˜ìŠ¤ë³„ ì£¼ìš” ë°œê²¬ì‚¬í•­
        class_summaries = {}
        for class_id, insights in class_insights.items():
            key_features_count = len(insights['key_features'])
            improvement_opportunities_count = len(insights['improvement_opportunities'])
            high_priority_opportunities = len([op for op in insights['improvement_opportunities']
                                             if op['priority'] == 'high'])

            class_summaries[class_id] = {
                'key_features_count': key_features_count,
                'top_3_features': list(insights['key_features'].keys())[:3],
                'improvement_opportunities': improvement_opportunities_count,
                'high_priority_improvements': high_priority_opportunities,
                'pattern_strength': round(insights['distinguishing_patterns']['positive_summary']['pattern_strength'], 3)
            }

        summary['class_summaries'] = class_summaries

        # ì „ì²´ì  ì¸ì‚¬ì´íŠ¸
        all_top_features = set()
        for model_summary in model_summaries.values():
            all_top_features.update(model_summary['top_features'])

        # ê°€ì¥ ì¼ê´€ë˜ê²Œ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤
        consistent_features = {}
        for feature in all_top_features:
            count = sum(1 for ms in model_summaries.values() if feature in ms['top_features'])
            if count > 1:
                consistent_features[feature] = count

        summary['global_insights'] = {
            'most_consistent_features': dict(sorted(consistent_features.items(),
                                                   key=lambda x: x[1], reverse=True)[:5]),
            'unique_important_features': len(all_top_features),
            'feature_consistency_ratio': len(consistent_features) / len(all_top_features) if all_top_features else 0
        }

        return summary

    def _log_results_to_tracker(self, analysis_result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œì— ê¸°ë¡í•©ë‹ˆë‹¤."""

        if not self.tracker:
            return

        summary = analysis_result['summary']

        # ë©”íŠ¸ë¦­ ê¸°ë¡
        metrics = {
            'shap_analysis/models_analyzed': summary['analysis_overview']['models_analyzed'],
            'shap_analysis/classes_analyzed': summary['analysis_overview']['classes_analyzed'],
            'shap_analysis/total_recommendations': summary['analysis_overview']['total_recommendations'],
            'shap_analysis/high_priority_recommendations': summary['analysis_overview']['high_priority_recommendations'],
            'shap_analysis/unique_important_features': summary['global_insights']['unique_important_features'],
            'shap_analysis/feature_consistency_ratio': summary['global_insights']['feature_consistency_ratio']
        }

        # ëª¨ë¸ë³„ ë©”íŠ¸ë¦­ ì¶”ê°€
        for model_name, model_summary in summary['model_summaries'].items():
            metrics[f'shap_analysis/{model_name.lower()}/features_concentration'] = model_summary['top_features_concentration']
            metrics[f'shap_analysis/{model_name.lower()}/avg_importance'] = model_summary['avg_shap_importance']

        # í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­ ì¶”ê°€
        for class_id, class_summary in summary['class_summaries'].items():
            metrics[f'shap_analysis/class_{class_id}/key_features_count'] = class_summary['key_features_count']
            metrics[f'shap_analysis/class_{class_id}/pattern_strength'] = class_summary['pattern_strength']
            metrics[f'shap_analysis/class_{class_id}/high_priority_improvements'] = class_summary['high_priority_improvements']

        self.tracker.log_metrics(metrics)

        # íŒŒë¼ë¯¸í„° ê¸°ë¡
        params = {
            'analysis_type': 'shap_interpretability',
            'models_count': summary['analysis_overview']['models_analyzed'],
            'problem_classes_analyzed': list(analysis_result['class_insights'].keys()),
            'most_important_feature': list(summary['global_insights']['most_consistent_features'].keys())[0] if summary['global_insights']['most_consistent_features'] else 'none'
        }

        self.tracker.log_params(params)

        print("ğŸ“ˆ SHAP ë¶„ì„ ê²°ê³¼ê°€ ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def get_recommendations(self) -> List[Dict[str, Any]]:
        """ìƒì„±ëœ ê¶Œì¥ì‚¬í•­ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.recommendations

    def print_summary(self, analysis_result: Dict[str, Any]):
        """SHAP ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""

        summary = analysis_result['summary']

        print("\n" + "="*60)
        print("ğŸ” SHAP ëª¨ë¸ í•´ì„ì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*60)

        # ë¶„ì„ ê°œìš”
        print(f"\nğŸ“Š ë¶„ì„ ê°œìš”:")
        print(f"  â€¢ ë¶„ì„ëœ ëª¨ë¸ ìˆ˜: {summary['analysis_overview']['models_analyzed']}ê°œ")
        print(f"  â€¢ ë¶„ì„ëœ ë¬¸ì œ í´ë˜ìŠ¤: {summary['analysis_overview']['classes_analyzed']}ê°œ")
        print(f"  â€¢ ìƒì„±ëœ ê¶Œì¥ì‚¬í•­: {summary['analysis_overview']['total_recommendations']}ê°œ")
        print(f"  â€¢ ê³ ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­: {summary['analysis_overview']['high_priority_recommendations']}ê°œ")

        # ëª¨ë¸ë³„ ì£¼ìš” ë°œê²¬ì‚¬í•­
        print(f"\nğŸ¤– ëª¨ë¸ë³„ ì£¼ìš” íŠ¹ì„±:")
        for model_name, model_summary in summary['model_summaries'].items():
            print(f"  [{model_name}]:")
            print(f"    - ìƒìœ„ 5ê°œ íŠ¹ì„±: {', '.join(model_summary['top_features'])}")
            print(f"    - íŠ¹ì„± ì§‘ì¤‘ë„: {model_summary['top_features_concentration']*100:.1f}%")
            print(f"    - í‰ê·  SHAP ì¤‘ìš”ë„: {model_summary['avg_shap_importance']:.4f}")

        # í´ë˜ìŠ¤ë³„ ì¸ì‚¬ì´íŠ¸
        print(f"\nğŸ¯ í´ë˜ìŠ¤ë³„ ì¸ì‚¬ì´íŠ¸:")
        for class_id, class_summary in summary['class_summaries'].items():
            print(f"  [Class {class_id}]:")
            print(f"    - í•µì‹¬ íŠ¹ì„± ìˆ˜: {class_summary['key_features_count']}ê°œ")
            print(f"    - ìƒìœ„ 3ê°œ íŠ¹ì„±: {', '.join(class_summary['top_3_features'])}")
            print(f"    - íŒ¨í„´ ê°•ë„: {class_summary['pattern_strength']:.3f}")
            print(f"    - ê°œì„  ê¸°íšŒ: {class_summary['improvement_opportunities']}ê°œ (ê³ ìš°ì„ ìˆœìœ„: {class_summary['high_priority_improvements']}ê°œ)")

        # ì „ì—­ ì¸ì‚¬ì´íŠ¸
        print(f"\nğŸŒ ì „ì—­ ì¸ì‚¬ì´íŠ¸:")
        print(f"  â€¢ ì´ ì¤‘ìš” íŠ¹ì„± ìˆ˜: {summary['global_insights']['unique_important_features']}ê°œ")
        print(f"  â€¢ íŠ¹ì„± ì¼ê´€ì„± ë¹„ìœ¨: {summary['global_insights']['feature_consistency_ratio']*100:.1f}%")

        if summary['global_insights']['most_consistent_features']:
            print(f"  â€¢ ê°€ì¥ ì¼ê´€ëœ íŠ¹ì„±ë“¤:")
            for feature, count in list(summary['global_insights']['most_consistent_features'].items())[:5]:
                print(f"    - {feature}: {count}ê°œ ëª¨ë¸ì—ì„œ ì¤‘ìš”")

        # ê³ ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­
        high_priority_recs = [r for r in self.recommendations if r['priority'] == 'high']
        if len(high_priority_recs) > 0:
            print(f"\nğŸš¨ ê³ ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(high_priority_recs[:3], 1):
                print(f"  {i}. [{rec['category']}]")
                print(f"     ë¬¸ì œ: {rec['issue']}")
                print(f"     í•´ê²°: {rec['solution']}")
                print(f"     ê¸°ëŒ€íš¨ê³¼: {rec['expected_impact']}")

        print("\n" + "="*60)
        print("âœ… SHAP ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“ ìƒì„¸ ì‹œê°í™”ëŠ” experiments/plots/shap_analysis/ ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    from ..utils.config import Config
    from ..tracking.experiment_tracker import ExperimentTracker
    import pandas as pd
    import numpy as np

    # ì„¤ì • ë¡œë“œ
    config = Config()

    # ì‹¤í—˜ ì¶”ì ê¸° ì´ˆê¸°í™”
    tracker = ExperimentTracker(
        project_name="dacon-smartmh-02",
        experiment_name="shap_interpretability_analysis"
    )

    # SHAP ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = SHAPAnalyzer(config=config, experiment_tracker=tracker)

    try:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„° ë¡œë“œ)
        print("ğŸ“ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")
        np.random.seed(42)
        n_samples = 2000  # SHAP ê³„ì‚° ì†ë„ë¥¼ ìœ„í•´ ì‘ê²Œ ì„¤ì •
        n_features = 52

        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°ì´í„° ìƒì„±
        class_probs = np.array([0.1, 0.08, 0.07, 0.06, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04,
                               0.04, 0.03, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01])
        class_probs = class_probs / class_probs.sum()

        # íŠ¹ì„± ë°ì´í„° ìƒì„±
        X = np.random.normal(0, 1, (n_samples, n_features))
        y = np.random.choice(21, size=n_samples, p=class_probs)

        # í´ë˜ìŠ¤ë³„ íŒ¨í„´ ì¶”ê°€
        for class_id in range(21):
            mask = y == class_id
            if mask.sum() > 0:
                pattern_features = np.random.choice(n_features, size=5, replace=False)
                for feat in pattern_features:
                    X[mask, feat] += np.random.normal(class_id * 0.3, 0.3, mask.sum())

        # DataFrame ìƒì„±
        feature_names = [f'feature_{i:02d}' for i in range(n_features)]
        X_df = pd.DataFrame(X, columns=feature_names)
        y_series = pd.Series(y)

        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(X_df)}í–‰ Ã— {len(X_df.columns)}ì—´, {y_series.nunique()}ê°œ í´ë˜ìŠ¤")

        # SHAP ë¶„ì„ ì‹¤í–‰
        results = analyzer.analyze_model_interpretability(
            X_train=X_df,
            y_train=y_series,
            problem_classes=[1, 0, 2],  # T007ì—ì„œ ì‹ë³„ëœ ë¬¸ì œ í´ë˜ìŠ¤
            top_features=20
        )

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_summary(results)

        return results

    except Exception as e:
        print(f"âŒ SHAP ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()