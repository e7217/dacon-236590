def main():
    """T010: Confusion Matrix ì‹¬í™” ë¶„ì„ì„ í†µí•œ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ í‰ê°€ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” T010: Confusion Matrix ì‹¬í™” ë¶„ì„ì„ í†µí•œ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    from src.analysis.confusion_matrix_analyzer import ConfusionMatrixAnalyzer
    from src.utils.config import Config
    from src.tracking.experiment_tracker import ExperimentTracker
    import pandas as pd
    import numpy as np
    from pathlib import Path

    try:
        # ì„¤ì • ë¡œë“œ
        config = Config()

        # ì‹¤í—˜ ì¶”ì ê¸° ì´ˆê¸°í™”
        tracker = ExperimentTracker(
            project_name="dacon-smartmh-02",
            experiment_name="T010_confusion_matrix_analysis"
        )

        # ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±
        data_path = Path("data")

        if not (data_path / "train.csv").exists():
            print("ğŸ“ SHAP ë¶„ì„ìš© ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            np.random.seed(42)
            n_samples = 2000  # SHAP ê³„ì‚° ì†ë„ë¥¼ ìœ„í•´ ì‘ê²Œ ì„¤ì •
            n_features = 52

            # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°ì´í„° ìƒì„±
            class_probs = np.array([0.1, 0.08, 0.07, 0.06, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04,
                                   0.04, 0.03, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01])
            class_probs = class_probs / class_probs.sum()

            # íŠ¹ì„± ë°ì´í„° ìƒì„± (ì„¼ì„œ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜)
            X = np.random.normal(0, 1, (n_samples, n_features))

            # íƒ€ê²Ÿ ìƒì„± (í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ íŒ¨í„´)
            y = np.random.choice(21, size=n_samples, p=class_probs)

            # í´ë˜ìŠ¤ë³„ë¡œ íŠ¹ì„±ì— íŒ¨í„´ ì¶”ê°€ (í•´ì„ê°€ëŠ¥í•œ íŒ¨í„´ ìƒì„±)
            for class_id in range(21):
                mask = y == class_id
                if mask.sum() > 0:
                    # ê° í´ë˜ìŠ¤ë§ˆë‹¤ íŠ¹ì • íŠ¹ì„±ë“¤ì— ê³ ìœ í•œ íŒ¨í„´ ë¶€ì—¬
                    pattern_features = np.random.choice(n_features, size=7, replace=False)
                    for feat in pattern_features:
                        X[mask, feat] += np.random.normal(class_id * 0.4, 0.4, mask.sum())

            # DataFrame ìƒì„±
            feature_names = [f'feature_{i:02d}' for i in range(n_features)]
            train_data = pd.DataFrame(X, columns=feature_names)
            train_data['target'] = y

            print(f"âœ… SHAP ë¶„ì„ìš© ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(train_data)}í–‰, {train_data['target'].nunique()}ê°œ í´ë˜ìŠ¤")

        else:
            print("ğŸ“‚ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
            train_data = pd.read_csv(data_path / "train.csv")

        # íŠ¹ì„±ê³¼ ë ˆì´ë¸” ë¶„ë¦¬
        X_train = train_data.drop(['target'], axis=1, errors='ignore')
        y_train = train_data['target']

        print(f"ğŸ“Š ë°ì´í„° ì •ë³´: {len(X_train)}í–‰ Ã— {len(X_train.columns)}ì—´")
        print(f"ğŸ¯ íƒ€ê²Ÿ í´ë˜ìŠ¤: {y_train.nunique()}ê°œ í´ë˜ìŠ¤")

        # Confusion Matrix ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = ConfusionMatrixAnalyzer(config=config, experiment_tracker=tracker)

        # Confusion Matrix ë¶„ì„ ì‹¤í–‰
        print("\nğŸ” Confusion Matrix ì‹¬í™” ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        results = analyzer.analyze_confusion_matrix_comprehensive(
            X_train=X_train,
            y_train=y_train
        )

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_summary(results)

        print("\nğŸ‰ T010: Confusion Matrix ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return results

    except Exception as e:
        print(f"âŒ T010 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()
