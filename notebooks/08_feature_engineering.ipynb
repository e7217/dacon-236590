{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Feature Engineering\n",
    "\n",
    "**Purpose**: Create new features from existing data to boost model performance\n",
    "\n",
    "**Techniques**: Polynomial features, statistical aggregations, interaction features\n",
    "\n",
    "**Expected Improvement**: +1-3% for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: What is Feature Engineering?\n",
    "\n",
    "### üé® The Analogy\n",
    "\n",
    "Imagine you're a detective trying to solve a mystery:\n",
    "- **Raw features**: Individual clues (height, weight, age)\n",
    "- **Engineered features**: Combining clues to create new insights\n",
    "  - Height + Weight ‚Üí BMI (body mass index)\n",
    "  - Age + Purchase history ‚Üí Customer lifetime value\n",
    "  - Temperature √ó Humidity ‚Üí Heat index\n",
    "\n",
    "**Key Insight**: Sometimes the combination of clues reveals more than individual clues!\n",
    "\n",
    "### üßÆ Three Types of Feature Engineering\n",
    "\n",
    "**1. Polynomial Features** üî¢\n",
    "- Create powers and products of features\n",
    "- Example: If you have `x` and `y`\n",
    "  - Degree 2: `x¬≤`, `y¬≤`, `x√óy`\n",
    "- Why useful? Captures non-linear relationships\n",
    "- Risk: Can create MANY features (need to be careful)\n",
    "\n",
    "**2. Statistical Aggregations** üìä\n",
    "- Calculate statistics across groups of features\n",
    "- Examples:\n",
    "  - Mean of all features\n",
    "  - Standard deviation (how spread out are values?)\n",
    "  - Min/Max (range of values)\n",
    "  - Percentiles (25th, 50th, 75th)\n",
    "- Why useful? Summarizes overall patterns\n",
    "\n",
    "**3. Interaction Features** ü§ù\n",
    "- Multiply or divide pairs of important features\n",
    "- Example: `Price √ó Quantity = Total Cost`\n",
    "- Why useful? Captures relationships between features\n",
    "- Best practice: Focus on the most important features\n",
    "\n",
    "### üìà Expected Results\n",
    "\n",
    "From research and past experience:\n",
    "- **QDA**: +1-2% (polynomial features help with non-linear boundaries)\n",
    "- **Tree models (RF, DT)**: +0.5-1.5% (explicit interactions help)\n",
    "- **SVC**: Variable (may help or hurt, depends on kernel)\n",
    "\n",
    "### ‚ö†Ô∏è Important Warnings\n",
    "\n",
    "1. **Memory explosion**: Polynomial features can create 1000+ features!\n",
    "2. **Overfitting risk**: Too many features ‚Üí model memorizes training data\n",
    "3. **Feature selection needed**: Must remove redundant/useless features\n",
    "\n",
    "Let's be smart about feature engineering! üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Load Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è∞ Start Time: 2025-10-01 02:57:38\n",
      "üé≤ Random State: 42\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"‚è∞ Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üé≤ Random State: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading models...\n",
      "\n",
      "‚ö†Ô∏è  QDA: Using BASELINE model (optimized version failed)\n",
      "    Reason: Optimization reduced F1 from 0.8782 ‚Üí 0.7553\n",
      "‚úÖ QDA (Baseline): F1 = 0.8782\n",
      "   Using default parameters (no optimization)\n",
      "‚úÖ RANDOMFOREST (Optimized): F1 = 0.7718\n",
      "   Best params: ['max_features_type', 'n_estimators', 'max_depth']...\n",
      "‚úÖ DECISIONTREE (Optimized): F1 = 0.7144\n",
      "   Best params: ['max_features_type', 'max_depth', 'min_samples_split']...\n",
      "\n",
      "‚úÖ Loaded scaler (MinMaxScaler)\n",
      "\n",
      "üìä Training Data:\n",
      "   Samples: 21,693\n",
      "   Features: 52\n",
      "   Classes: 21\n",
      "\n",
      "üí° Model Strategy:\n",
      "   QDA: Baseline (0.8782) - Best performer\n",
      "   RandomForest: Optimized (0.7718) - Improved from 0.7349\n",
      "   DecisionTree: Optimized (0.7144) - Slight improvement from 0.7105\n",
      "\n",
      "‚úÖ Ready for feature engineering!\n"
     ]
    }
   ],
   "source": [
    "# Load models from notebook 07\n",
    "print(\"üìÇ Loading models...\\n\")\n",
    "\n",
    "# Import model classes\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "models = {}\n",
    "\n",
    "# QDA: Use BASELINE (optimized version performed worse!)\n",
    "# From notebook 07: Optimized QDA got 0.7553, but baseline was 0.8782\n",
    "print(\"‚ö†Ô∏è  QDA: Using BASELINE model (optimized version failed)\")\n",
    "print(\"    Reason: Optimization reduced F1 from 0.8782 ‚Üí 0.7553\")\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model._metadata = {\n",
    "    'model_name': 'QDA',\n",
    "    'cv_f1_mean': 0.8782,  # Baseline F1 from notebook 06\n",
    "    'cv_f1_std': 0.0029,\n",
    "    'baseline_f1': 0.8782,\n",
    "    'best_params': {},  # Default parameters\n",
    "    'source': 'notebook 06 baseline'\n",
    "}\n",
    "models['qda'] = qda_model\n",
    "print(f\"‚úÖ QDA (Baseline): F1 = {qda_model._metadata['cv_f1_mean']:.4f}\")\n",
    "print(f\"   Using default parameters (no optimization)\")\n",
    "\n",
    "# RandomForest and DecisionTree: Use OPTIMIZED versions\n",
    "optimized_models = ['randomforest', 'decisiontree']\n",
    "for name in optimized_models:\n",
    "    model_path = f'../models/{name}_optimized.pkl'\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        models[name] = model\n",
    "        metadata = model._metadata\n",
    "        print(f\"‚úÖ {name.upper()} (Optimized): F1 = {metadata['cv_f1_mean']:.4f}\")\n",
    "        print(f\"   Best params: {list(metadata['best_params'].keys())[:3]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {name}: {e}\")\n",
    "\n",
    "# Load scaler\n",
    "scaler = joblib.load('../models/scaler_optimized.pkl')\n",
    "print(f\"\\n‚úÖ Loaded scaler (MinMaxScaler)\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('../data/open/train.csv')\n",
    "X = train_df.drop(['ID', 'target'], axis=1)\n",
    "y = train_df['target']\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"\\nüìä Training Data:\")\n",
    "print(f\"   Samples: {len(X):,}\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "print(f\"   Classes: {y.nunique()}\")\n",
    "\n",
    "# Setup cross-validation (same as notebook 07)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "f1_scorer = make_scorer(f1_score, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\nüí° Model Strategy:\")\n",
    "print(f\"   QDA: Baseline (0.8782) - Best performer\")\n",
    "print(f\"   RandomForest: Optimized (0.7718) - Improved from 0.7349\")\n",
    "print(f\"   DecisionTree: Optimized (0.7144) - Slight improvement from 0.7105\")\n",
    "\n",
    "print(f\"\\n‚úÖ Ready for feature engineering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polynomial Features\n",
    "\n",
    "### üî¢ What Are We Creating?\n",
    "\n",
    "From 52 features, we'll create:\n",
    "- **Original**: x‚ÇÅ, x‚ÇÇ, ..., x‚ÇÖ‚ÇÇ (52 features)\n",
    "- **Interactions**: x‚ÇÅ√óx‚ÇÇ, x‚ÇÅ√óx‚ÇÉ, ..., x‚ÇÖ‚ÇÅ√óx‚ÇÖ‚ÇÇ (~1,300 combinations)\n",
    "- **Total**: ~1,352 features\n",
    "\n",
    "### ‚ö†Ô∏è Memory Management\n",
    "\n",
    "**Strategy**: Use `degree=2` with `interaction_only=True`\n",
    "- ‚úÖ Creates useful feature pairs\n",
    "- ‚úÖ Avoids explosion (no x¬≤, x¬≥, etc.)\n",
    "- ‚úÖ Keeps memory usage reasonable\n",
    "\n",
    "If needed, we'll use feature selection to reduce to top 500-800 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Creating polynomial features...\n",
      "   Method: degree=2, interaction_only=True\n",
      "   Why? Captures feature relationships without memory explosion\n",
      "\n",
      "‚úÖ Polynomial features created!\n",
      "   Original features: 52\n",
      "   New features: 1378\n",
      "   Total features: 1,378\n",
      "   Time: 0.1 seconds\n",
      "   Memory: 239.1 MB\n",
      "\n",
      "üìù Example interactions:\n",
      "   1. X_01 X_02\n",
      "   2. X_01 X_03\n",
      "   3. X_01 X_04\n",
      "   4. X_01 X_05\n",
      "   5. X_01 X_06\n",
      "   ... and 1,321 more!\n"
     ]
    }
   ],
   "source": [
    "print(\"üî¢ Creating polynomial features...\")\n",
    "print(f\"   Method: degree=2, interaction_only=True\")\n",
    "print(f\"   Why? Captures feature relationships without memory explosion\")\n",
    "\n",
    "poly_start = time.time()\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(\n",
    "    degree=2,\n",
    "    interaction_only=True,  # Only x‚ÇÅ√óx‚ÇÇ, not x‚ÇÅ¬≤\n",
    "    include_bias=False       # Don't add constant column\n",
    ")\n",
    "\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "poly_feature_names = poly.get_feature_names_out(X_scaled.columns)\n",
    "\n",
    "poly_elapsed = time.time() - poly_start\n",
    "\n",
    "print(f\"\\n‚úÖ Polynomial features created!\")\n",
    "print(f\"   Original features: {X_scaled.shape[1]}\")\n",
    "print(f\"   New features: {X_poly.shape[1]}\")\n",
    "print(f\"   Total features: {X_poly.shape[1]:,}\")\n",
    "print(f\"   Time: {poly_elapsed:.1f} seconds\")\n",
    "print(f\"   Memory: {X_poly.nbytes / 1e6:.1f} MB\")\n",
    "\n",
    "# Show some example features\n",
    "print(f\"\\nüìù Example interactions:\")\n",
    "interaction_features = [f for f in poly_feature_names if ' ' in f]\n",
    "for i, feat in enumerate(interaction_features[:5]):\n",
    "    print(f\"   {i+1}. {feat}\")\n",
    "print(f\"   ... and {len(interaction_features) - 5:,} more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Aggregation Features\n",
    "\n",
    "### üìä What Statistics Are Useful?\n",
    "\n",
    "For each sample (row), we'll calculate:\n",
    "1. **Mean**: Average value across all features\n",
    "2. **Std**: How spread out are the feature values?\n",
    "3. **Min/Max**: Range of values\n",
    "4. **Median**: Middle value (50th percentile)\n",
    "5. **Q1/Q3**: 25th and 75th percentiles\n",
    "6. **IQR**: Inter-quartile range (Q3 - Q1)\n",
    "7. **Skewness**: Is the distribution lopsided?\n",
    "8. **Kurtosis**: How \"peaked\" is the distribution?\n",
    "\n",
    "These capture the **overall pattern** of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating statistical aggregation features...\n",
      "‚úÖ Statistical features created: 13\n",
      "\n",
      "üìù Features created:\n",
      "    1. mean\n",
      "    2. std\n",
      "    3. min\n",
      "    4. max\n",
      "    5. range\n",
      "    6. median\n",
      "    7. q25\n",
      "    8. q75\n",
      "    9. iqr\n",
      "   10. skew\n",
      "   11. kurt\n",
      "   12. mean_zscore\n",
      "   13. std_zscore\n",
      "\n",
      "üí° Why these help:\n",
      "   - Capture overall sample patterns\n",
      "   - Robust to individual feature noise\n",
      "   - Provide different 'views' of the data\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Creating statistical aggregation features...\")\n",
    "\n",
    "stat_features = pd.DataFrame()\n",
    "\n",
    "# Calculate statistics across all features for each sample\n",
    "stat_features['mean'] = X_scaled.mean(axis=1)\n",
    "stat_features['std'] = X_scaled.std(axis=1)\n",
    "stat_features['min'] = X_scaled.min(axis=1)\n",
    "stat_features['max'] = X_scaled.max(axis=1)\n",
    "stat_features['range'] = stat_features['max'] - stat_features['min']\n",
    "stat_features['median'] = X_scaled.median(axis=1)\n",
    "stat_features['q25'] = X_scaled.quantile(0.25, axis=1)\n",
    "stat_features['q75'] = X_scaled.quantile(0.75, axis=1)\n",
    "stat_features['iqr'] = stat_features['q75'] - stat_features['q25']\n",
    "stat_features['skew'] = X_scaled.skew(axis=1)\n",
    "stat_features['kurt'] = X_scaled.kurtosis(axis=1)\n",
    "\n",
    "# Z-scores (standardize)\n",
    "stat_features['mean_zscore'] = (stat_features['mean'] - stat_features['mean'].mean()) / stat_features['mean'].std()\n",
    "stat_features['std_zscore'] = (stat_features['std'] - stat_features['std'].mean()) / stat_features['std'].std()\n",
    "\n",
    "print(f\"‚úÖ Statistical features created: {len(stat_features.columns)}\")\n",
    "print(f\"\\nüìù Features created:\")\n",
    "for i, col in enumerate(stat_features.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nüí° Why these help:\")\n",
    "print(f\"   - Capture overall sample patterns\")\n",
    "print(f\"   - Robust to individual feature noise\")\n",
    "print(f\"   - Provide different 'views' of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaction Features (Top Features Only)\n",
    "\n",
    "### ü§ù Smart Feature Interactions\n",
    "\n",
    "Instead of creating ALL possible interactions, we:\n",
    "1. Find the **top 10 most important features** from our baseline models\n",
    "2. Create interactions ONLY among these top features\n",
    "3. This gives us ~45 interactions (10 choose 2) instead of 1,300+\n",
    "\n",
    "**Why?** Quality over quantity! The top features likely contain the most signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Finding most important features...\n",
      "\n",
      "üèÜ Top 10 most important features:\n",
      "    1. X_40: 0.9156\n",
      "    2. X_36: 0.9115\n",
      "    3. X_46: 0.8353\n",
      "    4. X_41: 0.8219\n",
      "    5. X_33: 0.8212\n",
      "    6. X_19: 0.8184\n",
      "    7. X_08: 0.7954\n",
      "    8. X_42: 0.7851\n",
      "    9. X_16: 0.7839\n",
      "   10. X_28: 0.7820\n",
      "\n",
      "ü§ù Creating interaction features...\n",
      "\n",
      "‚úÖ Interaction features created: 90\n",
      "   Products: 45\n",
      "   Ratios: 45\n",
      "\n",
      "üí° Why tree models love interactions:\n",
      "   - Trees split one feature at a time\n",
      "   - Explicit interactions help capture combined effects\n",
      "   - Example: 'age_x_income' might be more predictive than either alone\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Finding most important features...\")\n",
    "\n",
    "# Use mutual information to find top features\n",
    "mi_scores = mutual_info_classif(X_scaled, y, random_state=RANDOM_STATE)\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': X_scaled.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "# Get top 10 features\n",
    "top_n = 10\n",
    "top_features = mi_df.head(top_n)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nüèÜ Top {top_n} most important features:\")\n",
    "for i, (feat, score) in enumerate(zip(top_features, mi_df.head(top_n)['mi_score']), 1):\n",
    "    print(f\"   {i:2d}. {feat}: {score:.4f}\")\n",
    "\n",
    "# Create interaction features\n",
    "print(f\"\\nü§ù Creating interaction features...\")\n",
    "interaction_features = pd.DataFrame()\n",
    "\n",
    "# Pairwise products\n",
    "for i, feat1 in enumerate(top_features):\n",
    "    for feat2 in top_features[i+1:]:\n",
    "        col_name = f\"{feat1}_x_{feat2}\"\n",
    "        interaction_features[col_name] = X_scaled[feat1] * X_scaled[feat2]\n",
    "\n",
    "# Pairwise ratios (avoid division by zero)\n",
    "for i, feat1 in enumerate(top_features):\n",
    "    for feat2 in top_features[i+1:]:\n",
    "        col_name = f\"{feat1}_div_{feat2}\"\n",
    "        # Add small epsilon to avoid division by zero\n",
    "        interaction_features[col_name] = X_scaled[feat1] / (X_scaled[feat2] + 1e-8)\n",
    "\n",
    "print(f\"\\n‚úÖ Interaction features created: {len(interaction_features.columns)}\")\n",
    "print(f\"   Products: {len(top_features) * (len(top_features) - 1) // 2}\")\n",
    "print(f\"   Ratios: {len(top_features) * (len(top_features) - 1) // 2}\")\n",
    "\n",
    "print(f\"\\nüí° Why tree models love interactions:\")\n",
    "print(f\"   - Trees split one feature at a time\")\n",
    "print(f\"   - Explicit interactions help capture combined effects\")\n",
    "print(f\"   - Example: 'age_x_income' might be more predictive than either alone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection\n",
    "\n",
    "### ‚úÇÔ∏è Reducing Feature Count\n",
    "\n",
    "We now have:\n",
    "- Original: 52 features\n",
    "- Polynomial: ~1,300 features\n",
    "- Statistical: 13 features\n",
    "- Interaction: 90 features\n",
    "- **Total**: ~1,455 features\n",
    "\n",
    "This is TOO MANY! We need to select the best ones.\n",
    "\n",
    "### üéØ Selection Strategy\n",
    "\n",
    "1. **Remove highly correlated features** (correlation > 0.95)\n",
    "   - If two features are almost identical, keep only one\n",
    "2. **Select top K features** using mutual information\n",
    "   - Target: 200-500 features (manageable size)\n",
    "3. **Verify improvement** with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Combining all engineered features...\n",
      "üìä Feature counts:\n",
      "   Polynomial: 1,378\n",
      "   Statistical: 13\n",
      "   Interaction: 90\n",
      "   TOTAL: 1,481 features\n",
      "   Memory: 257.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Combine all engineered features\n",
    "print(\"üîó Combining all engineered features...\")\n",
    "\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly_feature_names)\n",
    "X_engineered = pd.concat([\n",
    "    X_poly_df,\n",
    "    stat_features.reset_index(drop=True),\n",
    "    interaction_features.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "print(f\"üìä Feature counts:\")\n",
    "print(f\"   Polynomial: {len(poly_feature_names):,}\")\n",
    "print(f\"   Statistical: {len(stat_features.columns)}\")\n",
    "print(f\"   Interaction: {len(interaction_features.columns)}\")\n",
    "print(f\"   TOTAL: {X_engineered.shape[1]:,} features\")\n",
    "print(f\"   Memory: {X_engineered.memory_usage(deep=True).sum() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Step 1: Remove highly correlated features...\n",
      "   Threshold: correlation > 0.95\n",
      "   Features to drop: 824 (highly correlated)\n",
      "   Remaining features: 657\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚úÇÔ∏è Step 1: Remove highly correlated features...\")\n",
    "\n",
    "# Calculate correlation matrix (takes time for many features)\n",
    "corr_threshold = 0.95\n",
    "print(f\"   Threshold: correlation > {corr_threshold}\")\n",
    "\n",
    "# Sample for speed (correlation patterns should be similar)\n",
    "sample_size = min(5000, len(X_engineered))\n",
    "X_sample = X_engineered.sample(n=sample_size, random_state=RANDOM_STATE)\n",
    "\n",
    "corr_matrix = X_sample.corr().abs()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "upper_triangle = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "to_drop = [col for col in upper_triangle.columns \n",
    "           if any(upper_triangle[col] > corr_threshold)]\n",
    "\n",
    "print(f\"   Features to drop: {len(to_drop)} (highly correlated)\")\n",
    "\n",
    "X_reduced = X_engineered.drop(columns=to_drop)\n",
    "print(f\"   Remaining features: {X_reduced.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Step 2: Select top features using mutual information...\n",
      "   Target: 300 features\n",
      "   Method: Mutual Information (measures relevance to target)\n",
      "\n",
      "‚úÖ Feature selection complete!\n",
      "   Original: 52 features\n",
      "   Engineered: 1,481 features\n",
      "   After correlation removal: 657 features\n",
      "   Final selected: 300 features\n",
      "   Reduction: 79.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüéØ Step 2: Select top features using mutual information...\")\n",
    "\n",
    "# Target number of features\n",
    "target_features = 300\n",
    "print(f\"   Target: {target_features} features\")\n",
    "print(f\"   Method: Mutual Information (measures relevance to target)\")\n",
    "\n",
    "# SelectKBest with mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k=target_features)\n",
    "X_selected = selector.fit_transform(X_reduced, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = X_reduced.columns[selected_mask].tolist()\n",
    "\n",
    "print(f\"\\n‚úÖ Feature selection complete!\")\n",
    "print(f\"   Original: {X_scaled.shape[1]} features\")\n",
    "print(f\"   Engineered: {X_engineered.shape[1]:,} features\")\n",
    "print(f\"   After correlation removal: {X_reduced.shape[1]:,} features\")\n",
    "print(f\"   Final selected: {X_selected.shape[1]} features\")\n",
    "print(f\"   Reduction: {(1 - X_selected.shape[1]/X_engineered.shape[1])*100:.1f}%\")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "X_final = pd.DataFrame(X_selected, columns=selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Retraining with Engineered Features\n",
    "\n",
    "Now let's retrain each model with our engineered features and compare performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Retraining models with engineered features...\n",
      "\n",
      "============================================================\n",
      "Model: QDA\n",
      "============================================================\n",
      "üìä Baseline (raw features):\n",
      "   F1: 0.8782 ¬± 0.0029\n",
      "\n",
      "üé® With engineered features:\n",
      "   F1: 0.8275 ¬± 0.0028\n",
      "   Time: 4.1 seconds\n",
      "\n",
      "üìâ Change: -0.0507 (-5.07%)\n",
      "   ‚ö†Ô∏è Raw features performed better for this model\n",
      "\n",
      "============================================================\n",
      "Model: RANDOMFOREST\n",
      "============================================================\n",
      "üìä Baseline (raw features):\n",
      "   F1: 0.7718 ¬± 0.0050\n",
      "\n",
      "üé® With engineered features:\n",
      "   F1: 0.7814 ¬± 0.0013\n",
      "   Time: 12.0 seconds\n",
      "\n",
      "üìà Change: +0.0096 (+0.96%)\n",
      "   ‚úÖ Feature engineering helped!\n",
      "\n",
      "============================================================\n",
      "Model: DECISIONTREE\n",
      "============================================================\n",
      "üìä Baseline (raw features):\n",
      "   F1: 0.7144 ¬± 0.0082\n",
      "\n",
      "üé® With engineered features:\n",
      "   F1: 0.7340 ¬± 0.0054\n",
      "   Time: 39.3 seconds\n",
      "\n",
      "üìà Change: +0.0196 (+1.96%)\n",
      "   ‚úÖ Feature engineering helped!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Retraining models with engineered features...\\n\")\n",
    "\n",
    "results_comparison = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Model: {name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get baseline performance\n",
    "    baseline_f1 = model._metadata['cv_f1_mean']\n",
    "    baseline_std = model._metadata['cv_f1_std']\n",
    "    \n",
    "    print(f\"üìä Baseline (raw features):\")\n",
    "    print(f\"   F1: {baseline_f1:.4f} ¬± {baseline_std:.4f}\")\n",
    "    \n",
    "    # Retrain with engineered features\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        model, X_final, y, cv=cv,\n",
    "        scoring={'f1_macro': f1_scorer},\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    engineered_f1 = cv_results['test_f1_macro'].mean()\n",
    "    engineered_std = cv_results['test_f1_macro'].std()\n",
    "    \n",
    "    print(f\"\\nüé® With engineered features:\")\n",
    "    print(f\"   F1: {engineered_f1:.4f} ¬± {engineered_std:.4f}\")\n",
    "    print(f\"   Time: {elapsed:.1f} seconds\")\n",
    "    \n",
    "    improvement = engineered_f1 - baseline_f1\n",
    "    print(f\"\\n{'üìà' if improvement > 0 else 'üìâ'} Change: {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(f\"   ‚úÖ Feature engineering helped!\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Raw features performed better for this model\")\n",
    "    \n",
    "    results_comparison.append({\n",
    "        'Model': name.upper(),\n",
    "        'Raw F1': baseline_f1,\n",
    "        'Raw Std': baseline_std,\n",
    "        'Engineered F1': engineered_f1,\n",
    "        'Engineered Std': engineered_std,\n",
    "        'Improvement': improvement,\n",
    "        'Improvement %': improvement * 100\n",
    "    })\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä FEATURE ENGINEERING RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "       Model Raw F1 Engineered F1 Improvement %\n",
      "         QDA 0.8782        0.8275        -5.07%\n",
      "RANDOMFOREST 0.7718        0.7814        +0.96%\n",
      "DECISIONTREE 0.7144        0.7340        +1.96%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìà Analysis:\n",
      "   Models improved: 2/3\n",
      "   Best improvement: DECISIONTREE (+1.96%)\n",
      "   Average improvement: -0.72%\n"
     ]
    }
   ],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results_comparison)\n",
    "comparison_df = comparison_df.sort_values('Engineered F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FEATURE ENGINEERING RESULTS SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "display_df = comparison_df[['Model', 'Raw F1', 'Engineered F1', 'Improvement %']].copy()\n",
    "display_df['Raw F1'] = display_df['Raw F1'].map('{:.4f}'.format)\n",
    "display_df['Engineered F1'] = display_df['Engineered F1'].map('{:.4f}'.format)\n",
    "display_df['Improvement %'] = display_df['Improvement %'].map('{:+.2f}%'.format)\n",
    "\n",
    "print(display_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nüìà Analysis:\")\n",
    "improved_models = comparison_df[comparison_df['Improvement'] > 0]\n",
    "print(f\"   Models improved: {len(improved_models)}/{len(comparison_df)}\")\n",
    "\n",
    "if len(improved_models) > 0:\n",
    "    best_improvement = comparison_df.loc[comparison_df['Improvement'].idxmax()]\n",
    "    print(f\"   Best improvement: {best_improvement['Model']} ({best_improvement['Improvement %']:+.2f}%)\")\n",
    "\n",
    "avg_improvement = comparison_df['Improvement'].mean()\n",
    "print(f\"   Average improvement: {avg_improvement*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Interpretation:\n",
      "   - Green bars higher than blue = feature engineering helped\n",
      "   - Green bars lower than blue = raw features were better\n",
      "   - Small differences suggest features had minimal impact\n"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Raw F1'], width,\n",
    "               label='Raw Features', alpha=0.8, color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Engineered F1'], width,\n",
    "               label='Engineered Features', alpha=0.8, color='seagreen')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('F1-Macro Score', fontsize=12)\n",
    "ax.set_title('Performance: Raw vs Engineered Features', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Model'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Interpretation:\")\n",
    "print(\"   - Green bars higher than blue = feature engineering helped\")\n",
    "print(\"   - Green bars lower than blue = raw features were better\")\n",
    "print(\"   - Small differences suggest features had minimal impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Improved Models and Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving models and feature transformer...\n",
      "\n",
      "‚è≠Ô∏è  Skipped QDA (no improvement)\n",
      "‚úÖ Saved RANDOMFOREST (improved by +0.96%)\n",
      "‚úÖ Saved DECISIONTREE (improved by +1.96%)\n",
      "\n",
      "‚úÖ Saved 2 improved model(s)\n",
      "\n",
      "‚úÖ Saved feature transformer to ../models/feature_transformer.pkl\n",
      "‚úÖ Saved results to ../outputs/feature_engineering_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"üíæ Saving models and feature transformer...\\n\")\n",
    "\n",
    "# Save models that improved with feature engineering\n",
    "saved_count = 0\n",
    "\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    model_name = row['Model'].lower()\n",
    "    improvement = row['Improvement']\n",
    "    \n",
    "    if improvement > 0:\n",
    "        # Retrain on full dataset with engineered features\n",
    "        model = models[model_name]\n",
    "        model.fit(X_final, y)\n",
    "        \n",
    "        # Add updated metadata\n",
    "        model._metadata['engineered_f1_mean'] = row['Engineered F1']\n",
    "        model._metadata['engineered_f1_std'] = row['Engineered Std']\n",
    "        model._metadata['engineered_improvement'] = improvement\n",
    "        model._metadata['n_engineered_features'] = X_final.shape[1]\n",
    "        model._metadata['feature_names_engineered'] = selected_features\n",
    "        \n",
    "        # Save\n",
    "        save_path = f'../models/{model_name}_optimized_engineered.pkl'\n",
    "        joblib.dump(model, save_path)\n",
    "        print(f\"‚úÖ Saved {model_name.upper()} (improved by {improvement*100:+.2f}%)\")\n",
    "        saved_count += 1\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  Skipped {model_name.upper()} (no improvement)\")\n",
    "\n",
    "if saved_count == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  No models improved with feature engineering\")\n",
    "    print(\"   Will use raw feature models for ensembles\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Saved {saved_count} improved model(s)\")\n",
    "\n",
    "# Save feature transformer pipeline\n",
    "feature_transformer = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('selector', selector)\n",
    "])\n",
    "\n",
    "transformer_path = '../models/feature_transformer.pkl'\n",
    "joblib.dump(feature_transformer, transformer_path)\n",
    "print(f\"\\n‚úÖ Saved feature transformer to {transformer_path}\")\n",
    "\n",
    "# Save results CSV\n",
    "csv_path = '../outputs/feature_engineering_results.csv'\n",
    "comparison_df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úÖ Saved results to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reflection: What Did We Learn?\n",
    "\n",
    "### ü§î Key Learnings\n",
    "\n",
    "**1. Which feature types helped most?**\n",
    "- Review the results above\n",
    "- Did polynomial features help linear models (QDA, SVC)?\n",
    "- Did interaction features help tree models (RF, DT)?\n",
    "\n",
    "**2. Did all models benefit equally?**\n",
    "- Some models may perform worse with engineered features\n",
    "- Why? Too many features can add noise and cause overfitting\n",
    "- This is NORMAL and expected!\n",
    "\n",
    "**3. Feature importance insights:**\n",
    "- The top 10 features identified were most informative\n",
    "- Combining these likely created the most useful interactions\n",
    "- Other features might have been redundant or noisy\n",
    "\n",
    "### ‚ö†Ô∏è Limitations\n",
    "\n",
    "**1. Feature Selection Trade-offs**\n",
    "- Removed many features (from 1,455 ‚Üí 300)\n",
    "- May have discarded some useful features\n",
    "- Could experiment with keeping 400-500 features\n",
    "\n",
    "**2. Computational Cost**\n",
    "- More features = longer training time\n",
    "- May not be worth the complexity for small gains\n",
    "\n",
    "**3. Model-Specific Results**\n",
    "- Feature engineering isn't always beneficial\n",
    "- Some models (especially well-tuned ones) may prefer raw features\n",
    "\n",
    "### üöÄ What Could We Try Next?\n",
    "\n",
    "**1. Domain-Specific Features**\n",
    "- If we knew more about what the features represent\n",
    "- Could create meaningful combinations\n",
    "\n",
    "**2. Automated Feature Engineering**\n",
    "- Tools like AutoFeat or Featuretools\n",
    "- Deep Feature Synthesis\n",
    "- May discover non-obvious feature combinations\n",
    "\n",
    "**3. Different Selection Methods**\n",
    "- Recursive Feature Elimination (RFE)\n",
    "- LASSO regularization\n",
    "- Feature importance from tree models\n",
    "\n",
    "**4. Ensemble Methods (Next!)**\n",
    "- Combine multiple models (with and without feature engineering)\n",
    "- Ensemble often beats best individual model\n",
    "- Expected: >89% F1 score\n",
    "\n",
    "### üìù Takeaways\n",
    "\n",
    "1. **Feature engineering is an art**: Not all features help all models\n",
    "2. **Feature selection is crucial**: Too many features can hurt performance\n",
    "3. **Always compare**: Engineered vs raw features in fair comparison\n",
    "4. **Domain knowledge matters**: Best features often come from understanding the data\n",
    "5. **Iterate**: First attempt may not work, but learning what doesn't work is progress!\n",
    "\n",
    "### üéØ Next Steps\n",
    "\n",
    "1. ‚úÖ Feature engineering complete\n",
    "2. ‚è≠Ô∏è Continue to Notebook 09: Ensemble Methods\n",
    "   - Combine models for better predictions\n",
    "   - Generate final competition submissions\n",
    "   - Achieve >89% F1 score goal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK 08 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "üìä Summary:\n",
      "   Original features: 52\n",
      "   Engineered features: 1,481\n",
      "   Selected features: 300\n",
      "   Models improved: 2/3\n",
      "\n",
      "‚û°Ô∏è Next: Notebook 09 - Ensemble Methods\n",
      "   Goal: Combine models to beat best individual performance\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ NOTEBOOK 08 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   Original features: 52\")\n",
    "print(f\"   Engineered features: {X_engineered.shape[1]:,}\")\n",
    "print(f\"   Selected features: {X_final.shape[1]}\")\n",
    "print(f\"   Models improved: {saved_count}/{len(models)}\")\n",
    "print(f\"\\n‚û°Ô∏è Next: Notebook 09 - Ensemble Methods\")\n",
    "print(f\"   Goal: Combine models to beat best individual performance\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ÏµúÏ¢Ö Î™®Îç∏ ÏÑ±Îä• Ï†ïÎ¶¨ Î∞è ÏïôÏÉÅÎ∏î Ï†ÑÎûµ\nprint(\"\\n\" + \"=\"*80)\nprint(\"üéØ Feature Engineering ÏµúÏ¢Ö Ï†ïÎ¶¨\")\nprint(\"=\"*80 + \"\\n\")\n\nprint(\"üìä Î™®Îç∏Î≥Ñ ÏµúÏ¢Ö ÏÑ±Îä•:\\n\")\n\nfinal_models = {\n    'QDA (Raw)': {\n        'F1': 0.8782,\n        'Features': 'Raw 52',\n        'Status': '‚úÖ ÏÇ¨Ïö© (ÏµúÍ≥† ÏÑ±Îä•)',\n        'File': 'N/A - Ïû¨ÌïôÏäµ ÌïÑÏöî'\n    },\n    'LogisticRegression (Raw)': {\n        'F1': 0.8762,\n        'Features': 'Raw 52',\n        'Status': '‚úÖ ÏÇ¨Ïö© (2ÏúÑ ÏÑ±Îä•)',\n        'File': 'N/A - Ïû¨ÌïôÏäµ ÌïÑÏöî'\n    },\n    'RandomForest (Engineered)': {\n        'F1': 0.7814,\n        'Features': 'Engineered 300',\n        'Status': '‚úÖ ÏÇ¨Ïö© (+0.96% Í∞úÏÑ†)',\n        'File': 'models/randomforest_optimized_engineered.pkl'\n    },\n    'RandomForest (Raw)': {\n        'F1': 0.7718,\n        'Features': 'Raw 52',\n        'Status': '‚ö†Ô∏è ÏÑ†ÌÉùÏ†Å (Îã§ÏñëÏÑ±)',\n        'File': 'models/randomforest_optimized.pkl'\n    },\n    'DecisionTree (Engineered)': {\n        'F1': 0.7340,\n        'Features': 'Engineered 300',\n        'Status': '‚ö†Ô∏è ÏÑ†ÌÉùÏ†Å (+1.96% Í∞úÏÑ†)',\n        'File': 'models/decisiontree_optimized_engineered.pkl'\n    },\n    'QDA (Engineered)': {\n        'F1': 0.8275,\n        'Features': 'Engineered 300',\n        'Status': '‚ùå ÏÇ¨Ïö© Í∏àÏßÄ (-5.07% Ï†ÄÌïò)',\n        'File': 'N/A - Ï†ÄÏû• Ïïà Ìï®'\n    }\n}\n\nfor model_name, info in final_models.items():\n    print(f\"„Äê{model_name}„Äë\")\n    print(f\"  F1-macro: {info['F1']:.4f}\")\n    print(f\"  Features: {info['Features']}\")\n    print(f\"  Status: {info['Status']}\")\n    print(f\"  File: {info['File']}\")\n    print()\n\nprint(\"=\"*80)\nprint(\"\\nüéØ ÏïôÏÉÅÎ∏î Ï†ÑÎûµ (Notebook 09):\\n\")\n\nensemble_strategies = {\n    'Strategy 1 (Í∂åÏû•)': {\n        'Models': ['QDA (Raw)', 'LogisticRegression (Raw)', 'RandomForest (Engineered)'],\n        'Expected F1': '0.88-0.89',\n        'Diversity': 'ÏÑ†Ìòï(2) + ÎπÑÏÑ†Ìòï(1)',\n        'Note': 'ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ Ï°∞Ìï©'\n    },\n    'Strategy 2': {\n        'Models': ['QDA (Raw)', 'RandomForest (Engineered)', 'RandomForest (Raw)'],\n        'Expected F1': '0.86-0.87',\n        'Diversity': 'Í∞ôÏùÄ Î™®Îç∏, Îã§Î•∏ features',\n        'Note': 'Feature Îã§ÏñëÏÑ± ÌôúÏö©'\n    },\n    'Strategy 3': {\n        'Models': ['QDA (Raw)', 'LogisticRegression (Raw)', 'RandomForest (Eng)', 'DecisionTree (Eng)'],\n        'Expected F1': '0.87-0.88',\n        'Diversity': 'ÏµúÎåÄ Îã§ÏñëÏÑ±',\n        'Note': 'Î™®Îç∏ + Feature Îã§ÏñëÏÑ±'\n    }\n}\n\nfor strategy_name, strategy_info in ensemble_strategies.items():\n    print(f\"„Äê{strategy_name}„Äë\")\n    print(f\"  Models: {', '.join(strategy_info['Models'])}\")\n    print(f\"  Expected F1: {strategy_info['Expected F1']}\")\n    print(f\"  Diversity: {strategy_info['Diversity']}\")\n    print(f\"  Note: {strategy_info['Note']}\")\n    print()\n\nprint(\"=\"*80)\nprint(\"\\nüìã Îã§Ïùå ÏûëÏóÖ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ (Notebook 09):\\n\")\n\nchecklist = [\n    ('‚úÖ', 'Feature Engineering ÏôÑÎ£å - 2/3 Î™®Îç∏ Í∞úÏÑ†'),\n    ('‚ö†Ô∏è', 'QDAÎäî Raw features ÏÇ¨Ïö© (Engineered Ïã§Ìå®)'),\n    ('üîú', 'QDA Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ Ïû¨ÌïôÏäµ (raw features)'),\n    ('üîú', 'LogisticRegression Î≤†Ïù¥Ïä§ÎùºÏù∏ Î°úÎìú/Ïû¨ÌïôÏäµ'),\n    ('üîú', 'Soft Voting Classifier Íµ¨ÏÑ±'),\n    ('üîú', 'Weighted Voting Ïã§Ìóò (ÏÑ±Îä• Í∏∞Î∞ò Í∞ÄÏ§ëÏπò)'),\n    ('üîú', 'Stacking Ensemble (meta-learner)'),\n    ('üîú', 'Competition submission ÏÉùÏÑ±'),\n    ('üéØ', 'ÏµúÏ¢Ö Î™©Ìëú: F1-macro ‚â• 0.89')\n]\n\nfor status, task in checklist:\n    print(f\"  {status} {task}\")\n\nprint(\"\\n\" + \"=\"*80)\n\n# Ï†ÄÏû•Îêú ÌååÏùº ÏöîÏïΩ\nprint(\"\\nüíæ Ï†ÄÏû•Îêú ÌååÏùº ÏÉÅÌÉú:\\n\")\n\nsaved_files = [\n    ('‚úÖ', 'models/randomforest_optimized_engineered.pkl', 'F1: 0.7814'),\n    ('‚úÖ', 'models/decisiontree_optimized_engineered.pkl', 'F1: 0.7340'),\n    ('‚úÖ', 'models/feature_transformer.pkl', 'Feature engineering pipeline'),\n    ('‚úÖ', 'outputs/feature_engineering_results.csv', 'Results summary'),\n    ('‚ö†Ô∏è', 'models/randomforest_optimized.pkl', 'F1: 0.7718 (raw, Îã§ÏñëÏÑ±Ïö©)'),\n    ('‚ö†Ô∏è', 'models/decisiontree_optimized.pkl', 'F1: 0.7144 (raw, Ï∞∏Í≥†Ïö©)'),\n    ('‚ùå', 'models/qda_optimized.pkl', 'F1: 0.7553 (ÏÇ¨Ïö© Í∏àÏßÄ!)'),\n]\n\nfor status, filepath, desc in saved_files:\n    print(f\"  {status} {filepath}\")\n    print(f\"      {desc}\")\n\nprint(\"\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Í≤∞Í≥º ÏÉÅÏÑ∏ Î∂ÑÏÑù Î∞è Í≤∞Î°†\n\n### üìä Feature Engineering Í≤∞Í≥º ÏöîÏïΩ\n\n| Î™®Îç∏ | Raw F1 | Engineered F1 | Í∞úÏÑ†Ïú® | Í≤∞Í≥º |\n|------|--------|---------------|--------|------|\n| **QDA** | 0.8782 | 0.8275 | **-5.07%** | ‚ùå ÏÑ±Îä• Ï†ÄÌïò |\n| **RandomForest** | 0.7718 | 0.7814 | **+0.96%** | ‚úÖ ÏÜåÌè≠ Í∞úÏÑ† |\n| **DecisionTree** | 0.7144 | 0.7340 | **+1.96%** | ‚úÖ Í∞úÏÑ† |\n\n### üéØ Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠\n\n#### 1. **QDA: Feature Engineering Î∂ÄÏ†ÅÌï©** ‚ùå\n\n**ÏÑ±Îä• Ï†ÄÌïò ÏõêÏù∏ Î∂ÑÏÑù:**\n\n1. **Î™®Îç∏ ÌäπÏÑ±Í≥º Î∂àÏùºÏπò**\n   - QDAÎäî Í∞Å ÌÅ¥ÎûòÏä§Ïùò Í≥µÎ∂ÑÏÇ∞ ÌñâÎ†¨ÏùÑ ÌïôÏäµ\n   - 52Í∞ú ÌäπÏÑ± ‚Üí 300Í∞ú ÌäπÏÑ±ÏúºÎ°ú Ï¶ùÍ∞Ä\n   - Í≥µÎ∂ÑÏÇ∞ ÌñâÎ†¨ ÌÅ¨Í∏∞: 52√ó52 ‚Üí 300√ó300 (35Î∞∞ Ï¶ùÍ∞Ä)\n   - ÏÉòÌîå Ïàò(21,693) ÎåÄÎπÑ ÌäπÏÑ± Ïàò ÎπÑÏú® ÏïÖÌôî\n\n2. **Ï∞®ÏõêÏùò Ï†ÄÏ£º (Curse of Dimensionality)**\n   - QDAÎäî Í≥†Ï∞®Ïõê Îç∞Ïù¥ÌÑ∞Ïóê Ï∑®ÏïΩ\n   - ÌäπÏÑ±Ïù¥ ÎßéÏïÑÏßàÏàòÎ°ù Í≥µÎ∂ÑÏÇ∞ Ï∂îÏ†ïÏùò Ïã†Î¢∞ÎèÑ ÌïòÎùΩ\n   - ÏõêÎ≥∏ 52Í∞ú ÌäπÏÑ±Ïù¥ QDAÏóê ÏµúÏ†Å\n\n3. **Ï†ïÍ∑úÌôî ÎØ∏Ìù°**\n   - QDA Î≤†Ïù¥Ïä§ÎùºÏù∏ÏùÄ `reg_param=0.0` (Í∏∞Î≥∏Í∞í)\n   - 300Í∞ú ÌäπÏÑ±ÏóêÎäî Îçî Í∞ïÌïú Ï†ïÍ∑úÌôî ÌïÑÏöî\n   - ÌïòÏßÄÎßå 07Î≤à ÎÖ∏Ìä∏Î∂ÅÏóêÏÑú Ï†ïÍ∑úÌôî ÏµúÏ†ÅÌôî Ïã§Ìå® Í≤ΩÌóò\n\n**ÍµêÌõà:**\n- **ÏÑ†Ìòï ÌåêÎ≥Ñ Î™®Îç∏ÏùÄ ÏõêÎ≥∏ ÌäπÏÑ±ÏùÑ ÏÑ†Ìò∏**\n- Feature engineeringÏù¥ Ìï≠ÏÉÅ ÎèÑÏõÄÏù¥ ÎêòÎäî Í≤ÉÏùÄ ÏïÑÎãò\n- Î™®Îç∏Ïùò ÏàòÌïôÏ†Å ÌäπÏÑ± Ïù¥Ìï¥ Ï§ëÏöî\n\n#### 2. **RandomForest: ÏÜåÌè≠ Í∞úÏÑ†** ‚úÖ\n\n**+0.96% Í∞úÏÑ† Î∂ÑÏÑù:**\n\n1. **Í∞úÏÑ† ÏöîÏù∏**\n   - Î™ÖÏãúÏ†Å interaction features Ï∂îÍ∞Ä\n   - Ìä∏Î¶¨ Î™®Îç∏ÏùÄ ÏûêÏ≤¥Ï†ÅÏúºÎ°ú interaction ÌïôÏäµÌïòÏßÄÎßå, Î™ÖÏãúÏ†Å Ï†úÍ≥µ Ïãú Îçî ÏâΩÍ≤å ÌïôÏäµ\n   - Statistical featuresÎ°ú Ï†ÑÏó≠ Ìå®ÌÑ¥ Ìè¨Ï∞©\n\n2. **Ï†úÌïúÏ†ÅÏù∏ Ïù¥Ïú†**\n   - Ïù¥ÎØ∏ ÏµúÏ†ÅÌôîÎêú Î™®Îç∏ (211 trees, depth 30)\n   - ÏõêÎ≥∏ ÌäπÏÑ±ÎßåÏúºÎ°úÎèÑ Ï∂©Î∂ÑÌïú ÏÑ±Îä•\n   - Feature engineeringÏùò ÌïúÍ≥Ñ\n\n3. **Í∏çÏ†ïÏ†Å Ï∏°Î©¥**\n   - ÏïàÏ†ïÏÑ± Ï¶ùÍ∞Ä (std: 0.0050 ‚Üí 0.0013)\n   - Î∂ÑÏÇ∞ Í∞êÏÜåÎäî ÏïôÏÉÅÎ∏îÏóêÏÑú Ïú†Î¶¨\n\n**ÍµêÌõà:**\n- **Ïù¥ÎØ∏ Ïûò ÌäúÎãùÎêú Î™®Îç∏ÏùÄ Ï∂îÍ∞Ä Í∞úÏÑ† Ïó¨ÏßÄ Ï†ÅÏùå**\n- ÏïàÏ†ïÏÑ± Ï¶ùÍ∞ÄÎèÑ Ï§ëÏöîÌïú Í∞úÏÑ†\n\n#### 3. **DecisionTree: Í∞ÄÏû• ÌÅ∞ Í∞úÏÑ†** ‚úÖ\n\n**+1.96% Í∞úÏÑ† Î∂ÑÏÑù:**\n\n1. **Ïôú Í∞ÄÏû• ÎßéÏù¥ Í∞úÏÑ†ÎêòÏóàÎÇò?**\n   - Î≤†Ïù¥Ïä§ÎùºÏù∏Ïù¥ Í∞ÄÏû• ÎÇÆÏùå (0.7144)\n   - Îã®Ïùº Ìä∏Î¶¨Îäî ÌëúÌòÑÎ†• Ï†úÌïú\n   - Engineered featuresÍ∞Ä Î≥µÏû°Ìïú Ìå®ÌÑ¥ÏùÑ Îã®ÏàúÌôî\n\n2. **Feature engineeringÏùò Ìö®Í≥º**\n   - Interaction features: Îëê ÌäπÏÑ±Ïùò Í¥ÄÍ≥ÑÎ•º Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï†úÍ≥µ\n   - Ìä∏Î¶¨Í∞Ä Ìïú Î≤àÏùò splitÏúºÎ°ú Î≥µÏû°Ìïú Ï°∞Í±¥ ÌëúÌòÑ Í∞ÄÎä•\n   - Statistical features: Ï†ÑÏó≠ Ìå®ÌÑ¥ÏùÑ Îã®Ïùº ÌäπÏÑ±ÏúºÎ°ú ÏöîÏïΩ\n\n3. **Ïó¨Ï†ÑÌûà ÌïúÍ≥Ñ**\n   - 0.7340ÏúºÎ°ú Ïó¨Ï†ÑÌûà Í∞ÄÏû• ÎÇÆÏùÄ ÏÑ±Îä•\n   - RandomForest(0.7814)Ïóê ÌÅ¨Í≤å Î™ª ÎØ∏Ïπ®\n   - Îã®Ïùº Ìä∏Î¶¨Ïùò Í∑ºÎ≥∏Ï†Å ÌïúÍ≥Ñ\n\n**ÍµêÌõà:**\n- **Î≤†Ïù¥Ïä§ÎùºÏù∏Ïù¥ ÎÇÆÏùÑÏàòÎ°ù Í∞úÏÑ† Ïó¨ÏßÄ ÌÅº**\n- Feature engineeringÏùÄ ÏïΩÌïú Î™®Îç∏Ïóê Îçî Ìö®Í≥ºÏ†Å\n\n### üîç Feature Î∂ÑÏÑù\n\n#### Top 10 Ï§ëÏöî Features\n```\n1. X_40: 0.9156\n2. X_36: 0.9115\n3. X_46: 0.8353\n4. X_41: 0.8219\n5. X_33: 0.8212\n6. X_19: 0.8184\n7. X_08: 0.7954\n8. X_42: 0.7851\n9. X_16: 0.7839\n10. X_28: 0.7820\n```\n\n**Í¥ÄÏ∞∞:**\n- ÏÉÅÏúÑ 2Í∞ú ÌäπÏÑ±(X_40, X_36)Ïù¥ ÏïïÎèÑÏ†Å\n- MI score 0.9 Ïù¥ÏÉÅ = Îß§Ïö∞ ÎÜíÏùÄ Ï†ïÎ≥¥Îüâ\n- Ïù¥ ÌäπÏÑ±Îì§Ïùò interactionÏù¥ Í∞ÄÏû• Ïú†Ïö©Ìï† Í≤É\n\n#### Feature Engineering Ìö®Í≥º\n```\n- Polynomial features: 1,378Í∞ú ÏÉùÏÑ±\n- Statistical features: 13Í∞ú ÏÉùÏÑ±\n- Interaction features: 90Í∞ú ÏÉùÏÑ±\n- Total: 1,481Í∞ú\n- ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Ï†úÍ±∞ ÌõÑ: 657Í∞ú\n- ÏµúÏ¢Ö ÏÑ†ÌÉù: 300Í∞ú (79.7% Í∞êÏÜå)\n```\n\n**Î∂ÑÏÑù:**\n- ÎåÄÎ∂ÄÎ∂ÑÏùò engineered featuresÎäî Ï§ëÎ≥µ\n- ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Ï†úÍ±∞Î°ú 824Í∞ú(55.7%) Ï†úÍ±∞\n- Mutual InformationÏúºÎ°ú 357Í∞ú Ï∂îÍ∞Ä Ï†úÍ±∞\n- **Ïßà > Ïñë**: 300Í∞úÎ°úÎèÑ Ï∂©Î∂Ñ\n\n### üí° ÏµúÏ¢Ö Í∂åÏû•ÏÇ¨Ìï≠\n\n#### **Î™®Îç∏Î≥Ñ Feature Ï†ÑÎûµ**\n\n1. **QDA** (0.8782)\n   - ‚úÖ **ÏõêÎ≥∏ 52Í∞ú ÌäπÏÑ± ÏÇ¨Ïö©**\n   - ‚ùå Engineered features ÏÇ¨Ïö©ÌïòÏßÄ Îßê Í≤É\n   - Ïù¥Ïú†: Ï∞®Ïõê Ï¶ùÍ∞ÄÎ°ú ÏÑ±Îä• Ï†ÄÌïò (-5.07%)\n   - ÌååÏùº: `qda` Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ Ïû¨ÌïôÏäµ\n\n2. **RandomForest** (0.7814)\n   - ‚úÖ **Engineered features ÏÇ¨Ïö©**\n   - Í∞úÏÑ†: +0.96%, ÏïàÏ†ïÏÑ± Ï¶ùÍ∞Ä\n   - ÌååÏùº: `models/randomforest_optimized_engineered.pkl`\n\n3. **DecisionTree** (0.7340)\n   - ‚úÖ **Engineered features ÏÇ¨Ïö©**\n   - Í∞úÏÑ†: +1.96%\n   - ÌååÏùº: `models/decisiontree_optimized_engineered.pkl`\n\n4. **LogisticRegression** (0.8762, from nb06)\n   - üîÑ **Feature Engineering ÏãúÎèÑ Í∂åÏû•**\n   - ÏÑ†Ìòï Î™®Îç∏Ïù¥ÏßÄÎßå QDAÏôÄ Îã§Î•∏ ÌäπÏÑ±\n   - L1/L2 Ï†ïÍ∑úÌôîÎ°ú Í≥†Ï∞®Ïõê Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Í∞ÄÎä•\n\n### üìà ÏïôÏÉÅÎ∏î Ï†ÑÎûµ ÏàòÎ¶Ω\n\n#### **Î™®Îç∏ Ï°∞Ìï© Ïö∞ÏÑ†ÏàúÏúÑ**\n\n**Option 1: ÏµúÍ≥† ÏÑ±Îä• Ï°∞Ìï©** (Í∂åÏû•)\n```\n- QDA (raw features): 0.8782\n- LogisticRegression (raw features): 0.8762\n- RandomForest (engineered features): 0.7814\n```\n- ÏòàÏÉÅ ÏïôÏÉÅÎ∏î ÏÑ±Îä•: **0.88-0.89**\n- Îã§ÏñëÏÑ±: ÏÑ†Ìòï(2) + ÎπÑÏÑ†Ìòï(1)\n\n**Option 2: Feature Îã§ÏñëÏÑ± Ï°∞Ìï©**\n```\n- QDA (raw features): 0.8782\n- RandomForest (engineered features): 0.7814\n- RandomForest (raw features): 0.7718\n```\n- ÏòàÏÉÅ ÏïôÏÉÅÎ∏î ÏÑ±Îä•: **0.86-0.87**\n- Îã§ÏñëÏÑ±: Í∞ôÏùÄ Î™®Îç∏, Îã§Î•∏ features\n\n**Option 3: Î™®Îç∏ Îã§ÏñëÏÑ± Ï°∞Ìï©**\n```\n- QDA (raw features): 0.8782\n- LogisticRegression (raw features): 0.8762\n- RandomForest (engineered features): 0.7814\n- DecisionTree (engineered features): 0.7340\n```\n- ÏòàÏÉÅ ÏïôÏÉÅÎ∏î ÏÑ±Îä•: **0.87-0.88**\n- Îã§ÏñëÏÑ± ÏµúÎåÄ, ÏïΩÌïú Î™®Îç∏ Ìè¨Ìï®\n\n### ‚ö†Ô∏è Ï£ºÏùòÏÇ¨Ìï≠ Î∞è Îã§Ïùå Îã®Í≥Ñ\n\n#### **Ï£ºÏùòÏÇ¨Ìï≠**\n\n1. **Feature ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ**\n   - Raw features Î™®Îç∏: ÏõêÎ≥∏ 52Í∞ú ÌäπÏÑ±Îßå\n   - Engineered features Î™®Îç∏: 300Í∞ú ÏÑ†ÌÉù ÌäπÏÑ±\n   - **ScalerÏôÄ transformer ÏùºÏπò ÌïÑÏàò**\n\n2. **Î™®Îç∏Î≥Ñ Îã§Î•∏ Ï†ÑÏ≤òÎ¶¨**\n   - QDA: `scaler_optimized.pkl` ÏÇ¨Ïö©\n   - RF/DT (engineered): `feature_transformer.pkl` Ï∂îÍ∞Ä ÌïÑÏöî\n\n3. **Ï†ÄÏû•Îêú ÌååÏùº ÌôïÏù∏**\n   ```\n   ‚úÖ models/randomforest_optimized_engineered.pkl\n   ‚úÖ models/decisiontree_optimized_engineered.pkl\n   ‚úÖ models/feature_transformer.pkl\n   ‚ùå QDA engineered (ÏÑ±Îä• Ï†ÄÌïòÎ°ú Ï†ÄÏû• Ïïà Ìï®)\n   ```\n\n#### **Îã§Ïùå Îã®Í≥Ñ (Notebook 09)**\n\n1. **Ï¶âÏãú ÏßÑÌñâÌï† ÏûëÏóÖ**\n   - ‚úÖ QDA Î≤†Ïù¥Ïä§ÎùºÏù∏ Î™®Îç∏ Ïû¨ÌïôÏäµ (raw features)\n   - ‚úÖ LogisticRegression Î≤†Ïù¥Ïä§ÎùºÏù∏ Î°úÎìú ÎòêÎäî Ïû¨ÌïôÏäµ\n   - ‚úÖ Voting Classifier Íµ¨ÏÑ± (soft voting Í∂åÏû•)\n   - ‚úÖ Stacking Ensemble Íµ¨ÏÑ± (meta-learner: LogisticRegression)\n\n2. **Ïã§ÌóòÌï† ÏïôÏÉÅÎ∏î Î∞©Î≤ï**\n   - Soft Voting: ÌôïÎ•† ÌèâÍ∑†\n   - Hard Voting: Îã§ÏàòÍ≤∞\n   - Weighted Voting: ÏÑ±Îä• Í∏∞Î∞ò Í∞ÄÏ§ëÏπò\n   - Stacking: Î©îÌÉÄ ÌïôÏäµÍ∏∞\n\n3. **ÏµúÏ¢Ö Î™©Ìëú**\n   - üéØ **F1-macro ‚â• 0.89** Îã¨ÏÑ±\n   - üìä Competition submission ÏÉùÏÑ±\n   - üèÜ ÏµúÏ¢Ö ÏàúÏúÑ ÌôïÏù∏\n\n### üìù ÌïµÏã¨ ÍµêÌõà\n\n1. **Feature Engineering ‚â† ÎßåÎä•**\n   - QDA Í∞ôÏùÄ ÌäπÏ†ï Î™®Îç∏ÏóêÎäî Ìï¥Î°úÏõÄ\n   - Î™®Îç∏Ïùò ÏàòÌïôÏ†Å ÌäπÏÑ± Ïù¥Ìï¥ ÌïÑÏàò\n\n2. **Ïù¥ÎØ∏ Ï¢ãÏùÄ Î™®Îç∏ÏùÄ Í∞úÏÑ† Ïñ¥Î†§ÏõÄ**\n   - QDA(0.8782), LR(0.8762)ÏùÄ Ïù¥ÎØ∏ near-optimal\n   - RFÎèÑ ÏµúÏ†ÅÌôî ÌõÑ Ï∂îÍ∞Ä Í∞úÏÑ† Ï†úÌïúÏ†Å (+0.96%)\n\n3. **ÏïΩÌïú Î™®Îç∏ÏùÄ Feature EngineeringÏúºÎ°ú Í∞úÏÑ†**\n   - DecisionTree: +1.96% (Í∞ÄÏû• ÌÅ∞ Í∞úÏÑ†)\n   - ÌïòÏßÄÎßå Ïó¨Ï†ÑÌûà Í∞ÄÏû• ÎÇÆÏùÄ ÏÑ±Îä•\n\n4. **ÏïôÏÉÅÎ∏îÏù¥ Ìï¥Îãµ**\n   - Îã®Ïùº Î™®Îç∏ ÌïúÍ≥Ñ: QDA 0.8782\n   - ÏïôÏÉÅÎ∏î Î™©Ìëú: **0.89+**\n   - Îã§ÏñëÏÑ±Ïù¥ ÌïµÏã¨\n\n5. **Always Validate**\n   - Í∞ÄÏ†ïÌïòÏßÄ ÎßêÍ≥† Ï∏°Ï†ï\n   - QDA engineered Ïã§Ìå®Î•º ÌÜµÌï¥ Î∞∞ÏõÄ\n   - Ïã§Ìå®ÎèÑ Ï§ëÏöîÌïú Ïù∏ÏÇ¨Ïù¥Ìä∏",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon-smartmh-02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}